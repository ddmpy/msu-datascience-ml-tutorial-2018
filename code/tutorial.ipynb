{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### at MSU Data Science 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'watermark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_ext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwatermark\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatermark\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-a \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSebastian Raschka\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -u -d -p numpy,scipy,matplotlib,sklearn,pandas,mlxtend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2294\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2292\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2294\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/core/magics/extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing module name.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malready loaded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m extension is already loaded. To reload it, use:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m module_str)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/core/extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/core/extensions.py:92\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m prepended_to_syspath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipython_extension_dir):\n\u001b[0;32m---> 92\u001b[0m         mod \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipython_extension_dir):\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;28mprint\u001b[39m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading extensions from \u001b[39m\u001b[38;5;132;01m{dir}\u001b[39;00m\u001b[38;5;124m is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe recommend managing extensions like any \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother Python packages, in site-packages.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m                   \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mcompress_user(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipython_extension_dir)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'watermark'"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a \"Sebastian Raschka\" -u -d -p numpy,scipy,matplotlib,sklearn,pandas,mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "- GitHub repository: https://github.com/rasbt/msu-datascience-ml-tutorial-2018\n",
    "- Slides: https://speakerdeck.com/rasbt/machine-learning-with-python         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [1 Introduction to Machine Learning](#1-Introduction-to-Machine-Learning)\n",
    "* [2 Linear Regression](#2-Linear-Regression)\n",
    "    * [Loading the dataset](#Loading-the-dataset)\n",
    "    * [Preparing the dataset](#Preparing-the-dataset)\n",
    "    * [Fitting the model](#Fitting-the-model)\n",
    "    * [Evaluating the model](#Evaluating-the-model)\n",
    "* [3 Introduction to Classification](#3-Introduction-to-Classification)\n",
    "    * [The Iris dataset](#The-Iris-dataset)\n",
    "    * [Class label encoding](#Class-label-encoding)\n",
    "    * [Scikit-learn's in-build datasets](#Scikit-learn's-in-build-datasets)\n",
    "    * [Test/train splits](#Test/train-splits)\n",
    "    * [Logistic Regression](#Logistic-Regression)\n",
    "    * [K-Nearest Neighbors](#K-Nearest-Neighbors)\n",
    "    * [3 - Exercises](#3---Exercises)\n",
    "* [4 - Feature Preprocessing & scikit-learn Pipelines](#4---Feature-Preprocessing-&-scikit-learn-Pipelines)\n",
    "    * [Categorical features: nominal vs ordinal](#Categorical-features:-nominal-vs-ordinal)\n",
    "    * [Normalization](#Normalization)\n",
    "    * [Pipelines](#Pipelines)\n",
    "    * [4 - Exercises](#4---Exercises)\n",
    "* [5 - Dimensionality Reduction: Feature Selection & Extraction](#5---Dimensionality-Reduction:-Feature-Selection-&-Extraction)\n",
    "    * [Recursive Feature Elimination](#Recursive-Feature-Elimination)\n",
    "    * [Sequential Feature Selection](#Sequential-Feature-Selection)\n",
    "    * [Principal Component Analysis](#Principal-Component-Analysis)\n",
    "* [6 - Model Evaluation & Hyperparameter Tuning](#6---Model-Evaluation-&-Hyperparameter-Tuning)\n",
    "    * [Wine Dataset](#Wine-Dataset)\n",
    "    * [Stratified K-Fold](#Stratified-K-Fold)\n",
    "    * [Grid Search](#Grid-Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import general packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='height:100px;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='height:100px;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='height:100px;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: R.J. Gladstone (1905). \"A Study of the Relations of the Brain to \n",
    "to the Size of the Head\", Biometrika, Vol. 4, pp105-123\n",
    "\n",
    "\n",
    "Description: Brain weight (grams) and head size (cubic cm) for 237\n",
    "adults classified by gender and age group.\n",
    "\n",
    "\n",
    "Variables/Columns\n",
    "- Gender (1=Male, 2=Female)\n",
    "- Age Range (1=20-46, 2=46+)\n",
    "- Head size (cm^3)\n",
    "- Brain weight (grams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a screenshot showing the top rows of the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/dataset_brain_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the dataset conveniently using pandas' CSV (comma separated values) reader. Note that the columns in the data file are actually not comma-separated; thus, we use the `'\\s+'` string, which is a regex shortcut specifying and arbitrary number of whitespaces as column separator. Typically, we use `sep=','` (the default) for comma-separated columns or `sep='\\t'` for tab-separated columns. Further, the `comment='#'` argument specifies that the first few lines of the dataset (here, a description of the dataset) should be skipped. The `encoding='utf-8'` is typically not necessary, but based on my experience in the past, omitting it can cause issues for some Windows users.\n",
    "\n",
    "Also, for more information on specific functions, you can always use the `?` operator in pandas (which is sometimes more convenient than looking for documentation online); e.g., copy and paste the following command into a new notebook cell and execute it to get more information: `pd.read_csv?`.\n",
    "\n",
    "Now, let's get back to reading the `dataset_brain.txt` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age-group</th>\n",
       "      <th>head-size</th>\n",
       "      <th>brain-weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3214</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3394</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3233</td>\n",
       "      <td>1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3352</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3391</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  age-group  head-size  brain-weight\n",
       "232       2          2       3214          1110\n",
       "233       2          2       3394          1215\n",
       "234       2          2       3233          1104\n",
       "235       2          2       3352          1170\n",
       "236       2          2       3391          1120"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_brain.txt',\n",
    "                 encoding='utf-8',\n",
    "                 comment='#',\n",
    "                 sep='\\s+')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's visualize the dataset using matplotlib.pyplot, which we imported as `plt` earlier. Here, we will only be looking at two variables, `'head-size'` and `'brain-weight'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Brain weight (grams)')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['head-size'], df['brain-weight'])\n",
    "plt.xlabel('Head size (cm^3)')\n",
    "plt.ylabel('Brain weight (grams)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that `'brain-weight'` is the target variable (which we want to predict) and `'head-size'` is the feature we use for the prediction, let's prepare the dataset for scikit-learn. I.e., we assign the `'brain-weight'` to an array `y` and the feature to an array `X` (a common convention when using scikit-learn):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['brain-weight'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['head-size'].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that scikit-learn expects 2D arrays as feature arrays; hence, we use `np.newaxis` to append another axis in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[:, np.newaxis]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both the targets and the features in a \"comfortable\" format, let's split the dataset into two separate, non-overlapping sets, a training and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, shuffle=True, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a fixed random seed to perform the split (here, `random_state=123`), which ensures that the data is always shuffled the same way prior to splitting -- this done is for reproducibility purposes. Note that you can choose any (positive) integer you like as a random seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see how our splits look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA7ZklEQVR4nO29e5gV1ZW4/S6ahm5BaRVmBhoRkkFUwIAQYn6oEUfFu63G6zgmEyeOfppEJxLFREF/IZKQMRn1i8ZMEM3EC0ZtNN6QUWK8IAFpBBQDBmK68RM0YkS6oWnW90dVNdWnq+rUudS59Fnv8/TDObvqVK0+VO+197qKqmIYhmEYUfQqtgCGYRhG6WPKwjAMw0iLKQvDMAwjLaYsDMMwjLSYsjAMwzDS0rvYAiTFwIEDdfjw4cUWwzAMo6xYvnz5B6o6KHW8xyqL4cOHs2zZsmKLYRiGUVaIyJ+Dxs0MZRiGYaTFlIVhGIaRFlMWhmEYRlp6rM8iiPb2dpqbm2lrayu2KBVPTU0NQ4cOpbq6utiiGIYRg4pSFs3Nzey9994MHz4cESm2OBWLqvLhhx/S3NzMiBEjii2OYRgxqChl0dbWZoqiBBAR9t9/f7Zs2VJsUQyjZ/CDeti5rft4n/5wfUteblFxPgtTFKWB/T8YRh4JUhRR41lQccrCMAzDyBxTFgVk69at/OxnP8vqsyeffDJbt26NPOfGG29k0aJFWV0/innz5nHllVdGnrN48WJeeeWVvN/bMIzSwJRFAYlSFh0dHZGffeqpp6irq4s85+abb+a4447LVrycMGVhGD0bUxYRNK5oYfLs5xlx3ZNMnv08jStycxRdd911vPPOO4wbN45p06axePFipkyZwoUXXsjYsWMBaGhoYMKECYwePZq7776787PDhw/ngw8+YOPGjRxyyCF8/etfZ/To0Zxwwgm0trYC8NWvfpXf/OY3nefPmDGDww8/nLFjx7J27VoAtmzZwvHHH8/hhx/Ov//7v3PggQfywQcfdJP1nnvu4aCDDuJLX/oSL7/8cuf4E088wRe+8AXGjx/Pcccdx/vvv8/GjRu56667+MlPfsK4ceP4/e9/H3ieYZQ6+f6b70mYsgihcUUL0x9dRcvWVhRo2drK9EdX5fTwzJ49m89+9rM0NTUxZ84cAJYuXcqsWbN48803AZg7dy7Lly9n2bJl3HbbbXz44YfdrrNu3TquuOIK1qxZQ11dHY888kjg/QYOHMjrr7/O5Zdfzo9//GMAbrrpJo499lhef/11zjzzTN59991un3vvvfeYMWMGL7/8Ms8991ynbABHHnkkS5YsYcWKFZx//vn86Ec/Yvjw4Vx22WVcffXVNDU1cdRRRwWeZxilTBJ/8wWjT//MxrOgokJnM2HOs2/T2t7VNNTa3sGcZ9+mYXx93u4zadKkLrkGt912G4899hgAf/nLX1i3bh37779/l8+MGDGCcePGATBhwgQ2btwYeO2zzjqr85xHH30UgJdeeqnz+ieeeCL77rtvt8+99tprHHPMMQwa5BSePO+88/jjH/8IOLkq5513Hu+99x47d+4MzZOIe55hlAqF+ptPhDyFx0ZhO4sQNm1tzWg8W/r169f5evHixSxatIhXX32VlStXMn78+MBs8759+3a+rqqqYteuXYHX9s7zn6OqseQKC239xje+wZVXXsmqVav4+c9/HpoNH/c8wygVCvU3X66YsghhSF1tRuNx2Hvvvfnkk09Cj3/88cfsu+++7LXXXqxdu5YlS5Zkfa8wjjzySObPnw/AwoUL+eijj7qd84UvfIHFixfz4Ycf0t7ezsMPP9xFxvp6Z5V17733do6n/m5h5xlGqZLE33xPIjFlISJzRWSziKxOGf+GiLwtImtE5Ee+8ekist49NtU3PkFEVrnHbpMCZXNNmzqK2uqqLmO11VVMmzoq62vuv//+TJ48mTFjxjBt2rRux0888UR27drFYYcdxg033MARRxyR9b3CmDFjBgsXLuTwww/n6aefZvDgwey9995dzhk8eDAzZ87ki1/8IscddxyHH35457GZM2dyzjnncNRRRzFw4MDO8dNOO43HHnus08Eddp5hlCpJ/M33JCSuWSLjC4scDWwD7lPVMe7YFOC7wCmqukNE/k5VN4vIocADwCRgCLAIOEhVO0RkKfAtYAnwFHCbqj6d7v4TJ07U1OZHb731Foccckjs36FxRQtznn2bTVtbGVJXy7Spo0rfdpmGHTt2UFVVRe/evXn11Ve5/PLLaWpqKoosmf5/GEbS9MS/+UwRkeWqOjF1PDEHt6q+KCLDU4YvB2ar6g73nM3u+BnAg+74BhFZD0wSkY3APqr6KoCI3Ac0AGmVRT5oGF/f4x6Ud999l3PPPZfdu3fTp08ffvGLXxRbJMMoGXri33y+KHQ01EHAUSIyC2gDrlHVPwD1ODsHj2Z3rN19nToeiIhcClwKMGzYsPxK3kMYOXIkK1asKLYYRiVTgKJ3Rv4ptLLoDewLHAF8HpgvIp8BgvwQGjEeiKreDdwNjhkqZ2kNo8QpS7NJAYreGfmn0MqiGXhUHUfJUhHZDQx0xw/wnTcU2OSODw0YN4yKx0si83IDvCQyoPQVhlF2FDp0thE4FkBEDgL6AB8AjwPni0hfERkBjASWqup7wCcicoQbBXUxsKDAMhtGSRKVRGYY+SaxnYWIPAAcAwwUkWZgBjAXmOuG0+4EvuLuMtaIyHzgTWAXcIWqen8FlwPzgFocx3ZBnNuGUepYEplRSBLbWajqBao6WFWrVXWoqv5SVXeq6kWqOkZVD1fV533nz1LVz6rqKH9orKouc8//rKpeqUnF+haAXEqUA/z0pz9l+/btac9bvHgxp556auQ5TU1NPPXUU1nLYhQfSyIzCollcBeQQimLOJiyKG3iVD8t2ySyAhS9M/KPFRIMI4HwPn+J8uOPP545c+YwZ84c5s+fz44dOzjzzDO56aab+PTTTzn33HNpbm6mo6ODG264gffff59NmzYxZcoUBg4cyAsvvNDl2s888wxXXXUVAwcO7JJxvXTpUq666ipaW1upra3lnnvuYcSIEdx44420trby0ksvMX36dEaMGNHtvFGjSnzS6aHEdVx7r8suGsrCY8sSUxZhJBDeN3v2bFavXt2ZMb1w4ULWrVvH0qVLUVVOP/10XnzxRbZs2cKQIUN48sknAafO0oABA7j11lt54YUXupXPaGtr4+tf/zrPP/88//iP/8h5553Xeezggw/mxRdfpHfv3ixatIjrr7+eRx55hJtvvplly5Zxxx13APC3v/0t8Dyj8GRS/dSSyIxCYcqiiCxcuJCFCxcyfvx4ALZt28a6des46qijuOaaa7j22ms59dRTOeqooyKvs3btWkaMGMHIkSMBuOiiizobJ3388cd85StfYd26dYgI7e3tgdeIe56RPD3ZcV2WeSEGYD6LoqKqTJ8+naamJpqamli/fj2XXHIJBx10EMuXL2fs2LFMnz6dm2++Oe21wuor3nDDDUyZMoXVq1fzxBNPhJYKj3uekTw91XFd1s2FDFMWhSS1jPfUqVOZO3cu27Y5pq2WlhY2b97Mpk2b2Guvvbjooou45ppreP311wM/73HwwQezYcMG3nnnHQAeeOCBzmP+UuHz5s0LlSXsPKPwlK3jOg2WF1LemLIoIKklyk844QQuvPBCvvjFLzJ27Fi+/OUv88knn7Bq1SomTZrEuHHjmDVrFt/73vcAuPTSSznppJOYMmVKl+vW1NRw9913c8opp3DkkUdy4IEHdh77zne+w/Tp05k8eTIdHXv+UKdMmcKbb77JuHHjeOihh0LPMwpPw/h6bjlrLPV1tQhQX1fLLWeNLXtzTU82r1UCiZUoLzY5lyi3YmeJYyXKK4vJs5+nJUAx1NfV8vJ1xxZBIiOIgpcoL3tMIRhGXpk2dVSXkGDoGea1SsGUhWEYBaFs80IMoAKVhaqGRg4ZhaOnmj+NaCwvpHypKAd3TU0NH374oU1URUZV+fDDD6mpqSm2KIZhxKSidhZDhw6lubmZLVu2FFuUiqempoahQ4emP9EwSphKSjKsKGVRXV3NiBEjii2GYRj5pEiRi5XWfKqilIVhGKVJTiv0IrVpzaSGV0/AlIVhlACVZM5IpVxX6JWWZFhRDm7DKEUqvWZSuZYB6ak1vMIwZWEYRaZcJ8t8Ua4r9J5awysMM0MZRpEp18kyXwypqw0sA1KMFXom5sBKSzI0ZWEYRaaUJstikGsZkPbe/aje9Wn3Axm2af1e4yp+veRdvCysOL6TSkoyTMwMJSJzRWSziKz2jc0UkRYRaXJ/TvYdmy4i60XkbRGZ6hufICKr3GO3iaVfGz2MSjNnpJJLld3GFS0ctmMuw9vu7/w5pOMhGs94M6Ow2cYVLV0UhUclmQPTkeTOYh5wB3BfyvhPVPXH/gERORQ4HxgNDAEWichBqtoB3AlcCiwBngJOBJ5OUG7DKCiVZs4IItsVer7CV+c8+3Y3ReFRKebAdCSmLFT1RREZHvP0M4AHVXUHsEFE1gOTRGQjsI+qvgogIvcBDZiyMHoYlWTOyCf58vdEnV8p5sB0FMNncaWIXAwsA76tqh8B9Tg7B49md6zdfZ06HoiIXIqzC2HYsGF5FtswKpAS7+uSL39P2HUEKsYcmI5Ch87eCXwWGAe8B/ynOx7kh9CI8UBU9W5VnaiqEwcNGpSjqIZhFCs7Oi758vcEXUeAfz5imO34XAq6s1DV973XIvIL4Lfu22bgAN+pQ4FN7vjQgHHDMBLECyF9udiCEB3Omi9/j/mN0lNQZSEig1X1PfftmYAXKfU4cL+I3Irj4B4JLFXVDhH5RESOAF4DLgZuL6TMhlFpdCm/UeQq8nFKgeTL32N+o2gSUxYi8gBwDDBQRJqBGcAxIjIOx5S0Efh3AFVdIyLzgTeBXcAVbiQUwOU4kVW1OI5tc24bRoIERRgVi0or1lfKJBkNdUHA8C8jzp8FzAoYXwaMyaNohmFEUEqhopWe3V5KWAa3YRSAcqoq648M2qY19Je27idlmB2dD1lSx43CYsrCMBKmnEpwN65oYfvOXZ3vx+yYCzgRRnGzqvNJrqVAjPxhVWcNI2HKpaqsp9Q+2t7eZbyutrooigJyKwVi5BfbWRgVS6FMQ+Vidw9zbPfr27uok7NFKZUGkcpCRIbi1Gw6CiektRUn3PVJ4GlV3Z24hIaRAIU0DZWL3b1clJpRHELNUCJyDzAX2An8ELgA+H+ARTjF/F4SkaMLIaRh5JtCmobKpapspXV+MzIjamfxn6q6OmB8NfCoiPQBrACTUZYUchVdLtnBYc7kxbsugpkh/SJKoD6UURhClUWQohCRfYEDVPUNVd0JrE9SOMNIikKbhsrB7h6m1KoXBCgKKJn6UEZhSOvgFpHFwOnuuU3AFhH5nar+R7KiGUZyWEhmMIFKbUFxZDFKizjRUANU9W8i8m/APao6Q0TeSFoww0iScjENZUyJlxQvd8opuTLfxFEWvUVkMHAu8N2E5TGMglEOpqGMKfGS4uVMOSVXJkEcZXEz8Czwkqr+QUQ+A6xLVizDqEDKcFfQuKIl9kRZ7qvySi9qmFZZqOrDwMO+938Czk5SKMOoSCJ2Bd5E+2zrBeG1mpJSKH36B8q2TWtir6x7wqq80vNQ4ji4RwDfAIb7z1fV05MTyzAMP95E278mQFFAYmamxhUtzOn1Kza1tdJLhA5NbVQZb2XdE1bl5ZJcmRRxzFCNOKXFnwAsY9swikAx+ks0rmhh2m9W0t7hKIjuisIhzsq6J6zKKz2CLo6yaFPV2xKXxDCM3AkxGWVTUvymJ9Z0Kooo4qysw1blvUQy8nsUkx4bQReTOMriv0RkBrAQ2OENqurriUllGEbGNK5ooSGPfovU6rNBxF1ZB63KwdmtFNJ3kauTvUdG0MUkjrIYC/wLcCx7zFDqvjcMI1+E7Arae/ejtroqrSmqkJOuQEaTrXfOt+ev7GbOKpTvoic42YtJHGVxJvAZt7yHYRgkFAYasiuoBm5x70eIfxvyP+nW1VaztbX77qKutpqmGSdkfL2G8fVc/VBT4LFC+C56gpO9mMRRFiuBOmBzsqIYRnlQjBVqp/ljZvR5QX6BbJl5+mimPbyS9t17dgLVvYSZp4/O/GJuDsmGmq7D27SGMTvmFiSiqCc42YtJnE55fw+sFZFnReRx7yfdh0RkrohsFpGggoTXiIiKyEDf2HQRWS8ib4vIVN/4BBFZ5R67TUQk7i9nGElQyp3vBEeZ5YOG8fXMOedzXbrUzTnnc9kpxJDQ3v7SVrCIIivBnhtxdhYzsrz2POAO4D7/oIgcABwPvOsbOxSnydJonCZLi0TkIFXtAO4ELgWWAE/h9NJ4OkuZDCNnklqh5sO0pZCbWSUli7zB/WGf/nBdMkl/hWqTGhn6WobZ84UmTgb377K5sKq+KCLDAw79BPgOXWtZngE8qKo7gA0ish6YJCIbgX1U9VUAEbkP59k1ZWEUjSSSs/Jp2spJaRWhtlSh/AWRoa8LrKZWOuJkcB8B3A4cAvQBqoBPVXWfTG8mIqcDLaq6MsWaVI+zc/Bodsfa3dep44ZRNJJIzsqH83V1368lb/8v8xV4JYe+5kocM9QdOCaih4GJwMXAyExvJCJ74VStDQqjCPJDaMR42D0uxTFZMWyYNfEzkiGJ5Kx8mLYKYv+3qrYVSxxlgaquF5Eq14dwj4i8ksW9PguMALxdxVDgdRGZhLNjOMB37lBgkzs+NGA8TM67gbsBJk6cmD711DCyJN8r1NimrbAMbZdC2f8zJo+Z5UZxiKMstrv9tptE5EfAe0C/TG+kqquAv/Peu/6Iiar6gRtddb+I3Irj4B4JLFXVDhH5xDWFvYazq7k903sbRqkT27R1fQvMHBB5rcmzn89sxxNmWsqGKDPVzI8z/0wZmLYqhTihs//inncl8CnODiBtiXIReQB4FRglIs0icknYuaq6BpgPvAk8A1zh7mIALgf+G6ff9zuYc9vogTSMr+eWs8Z2CVPNZpcw/dFVtGxtRdnjJE8bShtHUcTdAWRjpioF01bY72c7n04idxYiUgXMUtWLcHJHb4p7YVW9IM3x4SnvZwGzAs5bBoyJe1/DiKKUG/D4TVuenFc/1JSRnJk6yRtXtDihsWGE7QZ6GraDSUuksnDNQINEpI+V+zDKnXKpDRQlJ8BxWhPYAGmb1nQbg3AnuXefhqoMhMvF9xBkPrOVe9kQx2exEXjZ9St86g2q6q1JCWUYSVAutYHSZYhftWNut8/Ue47wHfHzPzrvk4myyPcK3KKoyoY4PotNwG/dc/f2/RhGWVEutYGi5Iw6Nm3qKGqru878UaG0+f6981VmxChN4mRwx/ZTGEYpUy5tMdPJGXbMn//RpVf3AvbUS/BFGHn32RZi1srEROSZtI7rFXKtKCystiyIk8H9BN0T4T4GlgE/V9UMnwzDKBx+h3bdXtVU95IuVVRLsS1mujBa/7HVfb/mTM5twExfLaewcpu+Sdm7zxifWau2uiqrKCzPpDWGriYyAX5y3jgaFhwa/mFzLpcFcXwWfwIGAQ+4788D3gcOAn6BE1prGCVHqqP4o+3tVFcJdbXVfNzaHjvKKDWCasrBg3hh7ZbuEVV5yheIkyHuHct4FZ/hfeISZtLqLGyYtZRGqRBHWYxX1aN9758QkRdV9WgRWZOUYIaRK0GO4vYOpV/f3rGb9zSuaOnS06Flayv/s6SzYHLXiKqIfIHJs59nysGDmN50PP1I7ytoAI6nlufOW95t8u6SPT4z1q/RhSTCh8NMZ+Aqkn3M1FTuxFEWg0RkmKq+CyAiwwCvD4WF0xolSz4c2jMfX9PFbBVEZ0RVxDmekvl+Tfx79yOZ0N4kwoenTR3F1Q81BRZuG1JXm1h5c6NwxImG+jbwkoi8ICKLgd8D00SkH3BvksIZRi7ko9lNUFvRIJKKqEqiqVISjZsaxtfzz0cM6+YqKUWfkJEdcaKhnhKRkcDBOP6qtT6n9k8TlM3IM6WcvZwxIf6BT6nluTMc000SpcTDGFJXG9kfOxeikuoaMrxWpol7mfD9hrFMPHC/nvOMGV0IVRYicqSqvgTgNiVamXJ8H2CYqnZrm2qUHuWSvRybEP9AkOkmdfKC+MX29t2rmo+2R+8uOhXQgsjTsiZoJ5QuVNXrbQ3OCm/D7FMAmDr7+YwS9zIlqX4RjStaOH7BhGB/jxUcLAhRZqizReQVEblRRE4RkUkicrSIfE1EfoWTqFdaAepGKKXcNzrf+H+vhvH1vHzdsWyYfQovX3cskFmxvRmnjaa6qqtxpaqXE1GVWvCvvXdwMeaw1XwcwnZCnaGqO+YyvO3+zh/vXv2ljY01F7Kx5kI21Fzo7MQg48S9UsBTjKGBAZYFXhBCdxaqerWI7At8GTgHGAy0Am/h5Fe8VBgRjXxQLtnL+SLs98q05Ecm4aXV39vULa9DFT5ua6feDbn9tKk2VjQUOCa1sJyHsN8vNJR25zZGXPckQ+pqOXtCfXDob4mSVVmSbLFy6aGkKyT4EU4uxS8KI46RFOWSvZwvwn6vbJRmJqaVtOc2/H+xrgNO05iGkGNRoapheDupR5a3lG6TpAAKuqAphXLpJUqcaCijB1CO5odUGle0MHn284y47snI86J+r3xESJUCYf+fcfCb6fzf6eTZz5dkfady+7/pqcRqq2qUP0n0jS4kqQ76sHpGQaYbv2loQG011VVCe0dAyY8sTBCBZqcMssPDrpXu86HO+5hO9k1bW8sm6MGLajOKS5zaUH3daKjIMaP0SSpSpRCk+hq8SJ/6utpOxzV0N92kTohbW9up7iXsu1c1W7f7JvWnJ2VsgggqJ+KR6cQbOXGHyNbQpz8NqUosprIYUldbNiXbPVk+XRDi77Es8IIQZ2fxKnB4jDHDSIxsHfSBJT92K3v16c2KG30lPxbEt0l7O4B0PoNMJt7IiTsTJRZSwdUfkeXtpK5+qCnwslF5HcXamTaMr4fx8f09Rv6JyrP4B6AeqBWR8eypY7kPsFcBZDOMTqIc9FGTWL6jwFJ3AOlocc096SbVSDljRt42rmhhTq9fsamt6/fwvcZVPPDaXwClSoSzJzg7zDCFF5XXUeomq5yxcumhRO0spgJfBYYC/q54nwDXJyiTYXRjysGDuhTw8xi+f23kJJbvKLCgHUA6pj28slOeMCLljJEZHjaZL/vzX3lkeQsd6vhoOlR5ZHkLEw/cL6MM93IxWeVMhYfHRhEaDaWq96rqFOCrqjrF93O6qj6a7sIiMldENovIat/Y/xWRN0SkSUQWisgQ37HpIrJeRN4Wkam+8Qkisso9dpuIhFXqN3owL6zdEji+5E8fRSYbxokCyyQCKJsdSftuZebj0QWac41WC5vMH3jtL5GT/C1njaW+rrYzwfDsCc6OIzU6Kszklmn4rlG+xPFZ/FZELgSG+89X1ZvTfG4ecAdwn29sjqreACAi3wRuBC4TkUOB84HRwBBgkYgcpKodwJ3ApcAS4CngRODpGHIbPYiwSdpbMYedH7c3REM6AX5QD9e3ZJXfAI5j3StTHpQQFylnDKd11PfT2SDJTxvwA8dB7t07ytRUJRL4XVfZ2q1iiKMsFuB0xlsOxI6AUtUXRWR4ytjffG/7sacD3xnAg26E1QYRWQ9MEpGNwD6q+iqAiNyHE+xiyqLCCJukwyYxv5kpXRTYpq2taF+InPdcO/a0qaO69LfIhMheGK6MgXLGsKNHfT9RWd1AZ8hwA9BQRWemtFdfas6zb4cq5bBxo+cRR1kMVdUT83VDEZkFXIyjgKa4w/U4OwePZnes3X2dOm5UGGH29bMn1PPI8pZuppbtO3fFciyDM9HGbTjXML6em55Yk7a4YFxi2f1j2NGjvh+a0nw4JNrKUzKbtrZSH6KM6i1hrmKIoyxeEZGxqpqXrBhV/S7wXRGZDlwJzCC4Y7BGjAciIpfimKwYNmxY7sIaxSEgOa4BOKVvP47p9z/d2pu2tncgdH0wPtreHjtaJ24ym1epNmotXVvdi9b23ekv5iMf5SwizVhNuV17dc0l9GvrHpW1TWtYNPX13C5ulA1RobOrcP7+egP/KiJ/wjFDCaCqeliO974feBJHWTQDB/iODQU2ueNDA8YDUdW7gbsBJk6caPvjciVkpVu961Ne/p6TgJdqXw/6z44brRPXL5DOV7HvXtW0ZagooLTLg9dWV4UWPuwvbT0rEsqIJGpncWq+byYiI1V1nfv2dGCt+/px4H4RuRXHwT0SWKqqHSLyiYgcAbyGY766Pd9yGeVH3BDWlq2tjL95YafZqK62mpmnj05kUlXt3oXOT6CjGWjf1Y/GFX8oyVIsb1WdV2wRjBIhqkT5nwFEZL+Aw5+ku7CIPAAcAwwUkWacHcTJIjIK2A38GbjMvdcaEZkPvAnsAq5wI6EALseJrKrFcWybc7sEKXR2byamG79/YWtre6y8h1TCelIIdP6+YRnRHmGO5updnyab8GaJZkYeiOOzeB3HRPQRzt9GHfCeiGwGvq6qy4M+pKoXBAz/MuwmqjoLmBUwvgwYE0NOo0gUI7s3Tghrqh/Do323djdPRZTJ8OpQpZJalypOCZAwgnIhvj1/JVc/1JS78k3nIA9TJobhI46yeAZ4TFWfBRCRE3ByHeYDPwO+kJx4RjlQjOzeoOif6l5C/5refLS9PTSk1iNXp3JQpdqXodMJ7O9Yly2e/Jko36x2eJ4ymTkga1mNnk+cfhYTPUUBoKoLgaNVdQnQNzHJjLIh7134wswjvvGg7OM553yOGaeNpra6Km38fzenckT4aH1dLRcdMazLvTrLoEd8LhdFkUqcFrjeDi9uy9icMTNWRRFnZ/FXEbkWeNB9fx7wkYhU4fgejAonzCQ0oLa6M9w0I1NKzPo8QdE/k2c/H8vxnUnTJ7+pKSlqq6vSyp1Nhd287fBmfpzb542yJ46yuBDHOd2IYwZ+yR2rAs5NTDKjbAgzCX26cxdbWx3ncqGqlMbZzey7V3XOMnjmnpdzuopLn/7cctJYjl8wITBM1fObpAuxzXmHZ45wI4K0ykJVPwC+EXJ4fX7FMcqRoISw7Tt3dctyLkSV0nSO79rqKmacNjqne3Rx6McsH96NlJV6A8CC8HyGOEUFc66wW6SKq8Xsk2HEJyop76eqepWIPEFAUImqnp6oZEZZkWoSCuuTnY9s5SiCdjleVFR9yETUuKIlfSFBH9mUKc+V1FaxQWRScrxUqJg+GT2AqJ3Fr9x/f1wIQYzyJnV1OKC2utME5Sdds6Jc8e9yWra2dkZFeYrilCc/Dws+7foZQDW4kOA2rWF24yq+3zC2c8yv8MJ6gXeabvJk1onz/YT25YbsfEcFoGL6ZPQAopLylrv//k5EaoFhqhodjmFUJEGrw+oqCS2Nva2xhqvc3IUkVpLedVJlmvbwShr6fBr4GREY3nZ/8AXdSrGewvCbe/w5GKl5F8UgdYdX6iv3vEfSGYmRNnRWRE7DKUX2jPt+nIg8nrBcRhnhXx2u7vs1NtZcyLrqC0JDR1PHo8JCG1e0MHn2892a8WQik0c2ZcU9nLakDkGNigSnm19izBzQ/ecHufX2LgXC/Cn5qpdl5I840VAzgUnAYgBVbUrtU2FUNv5VYLa5BUEryWxWxZ6J69nWC+hfk788B3/eRsP4epb9+a/8esm7nc48hc52pVmv2DPNpI5xbqmv3MvRz1KpxFEWu1T1Y+tmWkEElAgHnMksIGIm2+5xfnqJdOs/kak9269c8qkooHtHuBfWbukW9ZGzrT3gu21c0ULDgkOzux55iJBKmDidDI3SII6yWO22Va0SkZHAN4FXkhXLKCphK9aUcW8V37K1NbQOU1w6VLvtGqJWxUFO8iSjlC74wgFd3qddsWeocMOI1fI1gnJYuSdRWt3IP3HKfXwDpzf2DuABnA53VyUok1EG+EtLQHinqjCCejen2tLDVr8DaqsDy1rksrvZpjWh/aT79anqEg0VJVvdXtXOi5gKNx25mouCyqLECcM1jFTi7Cz+wetul7QwRvGJm3MQtIqPvbPo05/dbcFn+yfHsJyJ9o7dgeapuEyueaxL1JK3S+nY0X2HVFtdxawzx3a7xrSpo5j2m5W0d3T9Pba17co4byOKIXW1kKNFzVbuRj6IoyzmiUg98AfgReD3+WqxapQW3m6hoSr9uWEr3rC8g/be/aj+3p4mh0NmP5/Wlh7mSP50Z26mJr8JJqjjXrokPk+2mY+v6ZZL0r5buemJNXlTFtOmjmJbY5pcDsib2cswwohT7uNoEekDfB6nmdGTItJfVYOaIhllTOduIYayCHOcTq19oNN/4PkTFu+6iOpdn3Ypgf0ysK1vQBnvNpz4O3eSm950PN+vCa+XFEaU0krnRPcURbqciY8Dkg7BbbaUbRmQFBrG19PI6+kdwHkyexlGGGmVhYgcCRzl/tQBvwV+n6xYRjHwdgtps5KJdpx2M3vMDE6Eiwyz3bkNflAf2f85iiBFUltdxS1njO2y6s8ltDQfUWBxMDOSUQrEMUP9DlgG3AI8pao7kxXJKBbe5Bc60Z60Z6ItSMhjmlVxlQi7VemVptGRR1Boay6hpdOmjuKqNK1UDaOnEEdZ7A9MBo4Gvikiu4FXVfWGRCUzCk7QbsEjaKIt9op3tyobZp/Sze8QRWrY7YDaaqqrpIuj2h9aGlXHKsxvkQRWmdUoNnF8FltF5E84fbiHAv8HqE5aMKPweJNP2Gq5VLJ+PbzVf9Au59MduwIncS/s1lMsW1vbqe4l7LtXNVu3t3eZiIMyyI9rPBwW7DGBNQHUdPWhpJYCyZawPJZSq+9kVAZxfBbvAG/j+CnuAv7VTFE9E29yCqNUsn49/FFN6QrogTOJi3QPs23frezVpzcrbjyhy3iQ8zuq3pXAnkqvC7L9rYLlT5stbo2LjISJY4YaqaoZt08VkbnAqcBmVR3jjs0BTgN2Au/gKJ6t7rHpwCVAB/BNr++3iEwA5gG1wFPAt1RjGKiNjEhnysmpUF66iSzgWKiT3SU1qimVMJ/K1RnsmjLdSW2YfcqeN0/nNnnHyUbvIp+FxxoJE8cMlW2f7XnAHcB9vrHngOmquktEfghMB64VkUOB83EyxYcAi0TkIFXtAO4ELgWW4CiLE4Gns5TJCCHd5JRTobw0E9nkkJyLNTWXBEdD9elPdYzJMcin4pl1UgnaNeUU7ZTj5B03GsswCkWcnUVWqOqLqdVpVXWh7+0S4Mvu6zOAB1V1B7BBRNYDk0RkI7CPqr4KICL34fSqMWWRZ+JMTnlpShOQPOblXKRGYY1u+yW11VXdTEleVFY2Tt9MaiVFOfyTJk572FKq72T0fOLUhkqKr7Fn0q8H/uI71uyO1buvU8cDEZFLRWSZiCzbsmVLnsXt2cRdpebs5A4Jhw0yOQnd/QuewvLXpvLXh0rX7yKTWklB5xaKsJ4ZYPWdjOIQx8HdFzgbGO4/X1VvzvamIvJdYBfwa28o4LSw2nSh/gpVvRu4G2DixInm18iAuKvoQpo+wv4DN21tzakdZyYhv93O/UFhHMlWutsoNeKYoRbgVJpdjlN5NidE5Cs4ju9/8jmqm3FCcz2GApvc8aEB40aeSZ2c6vaqZlvbri7d5UrF9DGkrrZ4TX0K6Egudh6LYfiJoyyGquqJ+biZiJwIXAt8SVW3+w49DtwvIrfiOLhHAktVtUNEPhGRI4DXgIuB2/MhSyUR17bvn5waV7Rw0xNrnDpHwJqar9GPNmfp4A8LjYhoSqKInaewMnFU54olxBlGPGXxioiMzbTSrIg8gFN4cKCINAMzcKKf+gLPuZ33lqjqZaq6RkTmA2/imKeucCOhAC5nT+js05hzOyOybU2aapLqF1YnO6okR45F7Fb3/Vpw+OzT/eGkpQVp6pPN92cYPZE4yuJI4KsisgHHDCWAquphUR9S1QsChn8Zcf4sYFbA+DJgTAw5jQCyaU367fkrY9Vayob23v2cCrQpbKf7jiA0z2LnNhqengRnLU18xZ+Lb8QwehJxlMVJiUthJEaYDT/IhOOtopNSFADH9P4fWrZ1v3fGHd53biuITb9ovhHDKDFClYWI7KOqfwM+KaA8Rp4Ji9cX6Awz9Vbncau3Zowvt+Jl6Oz14K+nVKqha2Hfn+IkE+ZlN2ONi4wyIGpncT9O1NJyuoexKvCZBOUy8oRX4iJ1MlbgpifW0Na+p0VpYjuKDHIr8kE+HdJRIcV5819Y4yKjDAhNylPVU91/R6jqZ9x/vR9TFGVCw/j60FX7R9vbY2cnb9OQ1m99+ofnGMTMPcjYBBVBtsl6YfgT84Lw/BeG0dOJVe5DRPbFCWftnDFU9cWkhDLyS30ONY6qq4R+fXoztnVuIk7k+rpaphw8iEeWt3RRXEL6YoJBJOGQ9nwjI657MlDxmv/CqATiZHD/G/AtnIS4JuAI4FUgukGxUVzS+Alqq6vo27tXYM8HrwNdIXIKvD7XEw/cr1vvhjE75oaHz4bsWpJ0SOfSVc8wyp04O4tvAZ/HyYmYIiIHAzclK5aRMxF+gnqv5wIE5ioUo+6Qt3pPrUDrOcDr62o7FUsUSU7omRQhNIyeRhxl0aaqbSKCiPRV1bUiYn8dZUzqpJt4dnIGjXly3RkkOaEnVq/JGhcZZUAcZdEsInVAI07m9UdYfaYeQxK5Ct2ikU5aGvseYTuDXiKMuO7JtBN00gX4EsntsPBYowyI0/zoTPflTBF5ARgAPJOoVEbZkmt5jLBQVS+sN871rACfYeSfSGUhIr2AN7y2qKr6u4JIZZQtcaORwnIhUncGQYmCcaObrACgYeSPSGWhqrtFZKWIDFPVdwsllBFAplm+RbKDx/E5pNt9NIyvd2o/1QT35h6zY25aH4YVADSM/BLHZzEYWCMiS4HOCnCqenpiUhndyTTLNw928GxW5nGikWLtPtJkfaeLbsok38J2IIaRnjjKwsJkK5BsV+ZxopFyjXiq7iVpo5vi3sN2IIYRjzgO7k4/hYgMBD70dbgzSpRcV8vZZkJHRSN5MoU9PHFzIfrX9M7LDseT00qQG0Z6oqrOHgHMBv4K/F/gV8BAoJeIXKyqFhFVouRjtZzL6j8oGimooZKfTHIhvO59UcTNt7AS5IYRj9BCgsAdwA+AB4DngX9T1X8AjgZuKYBsRpZErZbjErbKzzYTOkgmj/q62oyyxqskfelBfwFAibhHvn9Pw+ipRJmheqvqQgARuVlVlwC4GdwFEc7wUcAsaIhemWdj4gq7t9A9oxwI/X23aU3sUupx8i2shIdhxCNKWez2vU79SzefRaHJILopH/WRwnwPQGwTl1+phDVWCpXp+pZudaI8wsqFZ0PSGd+G0VOQMF+1iHTghMoKUAts9w4BNapaXRAJs2TixIm6bNmyYotRFIL8A/kqEBg2gQOdBQo9Z3aUjyKOTFn9HtZ1zjByQkSWq+rE1PHQnYWqVuV4w7k4nfY2exngInIOMBM4BJikqst8508HLgE6gG+q6rPu+ARgHo7Cegr4lkVjRZPTajnNZBtlyvLvMsJ8FJmUP8/q97Cuc4aRCLGaH2XJPBwn+X2+sdXAWcDP/SeKyKHA+cBoYAiwSEQOUtUO4E7gUmAJjrI4EXg6Qbl7BFnXR0oz2YaZuDw8R3qYUtmtyobZpwQeS1cCxDCM4hEVDZUTbie9v6aMvaWqQSE5ZwAPquoOVd0ArAcmichgYB9VfdXdTdwHNCQls5GeaVNHUVsdven0Jvsgwsbz3Q7VMIz8kpiyyJB64C++983uWL37OnU8EBG5VESWiciyLVu2JCJoKdC4wnH+jrjuSSbPfr6gE2q6ntRA564gValERRnlI9zXMIzkKBVlERSLqxHjgajq3ao6UVUnDho0KG/ClRKlsAJvGF/Py9cdy0/PGxeqEOLmOXhYcpxhlDZJ+iwyoRk4wPd+KE6DpWb3dep4xVJK5SnSOaAz8TfkrR2qdZ0zjEQoFWXxOHC/iNyK4+AeCSxV1Q4R+cQtPfIacDFwexHlLDqZrsCDnMYQEWGU4WSbLwd03pLjLDzWMBIhMWUhIg8AxwADRaQZmIHj8L4dGAQ8KSJNqjpVVdeIyHzgTWAXcIUbCQVwOXtCZ5+miJFQpVDKOpMVeFCNqGkPrwSB9o6QznP5nmxj5j1YcpxhlDahSXnlTr6T8pJMdEu9T9SEmYkcUQl0qdTX1QaX3ciVmQMijn2c//sZhpETYUl5peLgLnkKEa0Tx3mdieM4E+ewOZINw4iiVHwWJU8honXiOq/j+gnSJdClnmsYhhGGKYuY5C1aJ4JnWy+gf01bt/FtrTXA+xlfL8hpXN1LuvgsIDtHcin4bwzDKBxmhopJpklm2eD1l447no4gk9Wccz7HnC9/Lnb+QxClkOthGEZhsZ1FTMo1WifMZJWL3Bnleljeg2H0CExZZIAVtXPIyH9jeQ+G0SMwM5SRMdaK1DAqD1MWRsYUwn9jGEZpYWaoUqJM7Pvl6r8xDCN7LIPbMAzD6MQyuA3DMIysMWVhGIZhpMV8FgliWc6GYfQUTFkkRFB58C6lwJMmZmlwwzCMOJgZKiGK3lM6SFFEjRuGYURgyiIhrKe0YRg9CVMWCRGWzdxLxAruGYZRdpiySIigLGeADlWr0GoYRtlhyiIhvPLgVSLdjhXUd2EYhpEHTFkkSMP4enaHZMgn7rsIKxFSYqVDDMMoDxILnRWRucCpwGZVHeOO7Qc8BAwHNgLnqupH7rHpwCVAB/BNVX3WHZ8AzANqgaeAb2kZ1SgpRIe9QCw81jCMPJLkzmIecGLK2HXA/6rqSOB/3feIyKHA+cBo9zM/ExHP4H8ncCkw0v1JvWZJYxVaDcPoCSSmLFT1ReCvKcNnAPe6r+8FGnzjD6rqDlXdAKwHJonIYGAfVX3V3U3c5/tMWRDU2jTTNqaGYRjFptAZ3H+vqu8BqOp7IvJ37ng9sMR3XrM71u6+Th0PREQuxdmFMGzYsDyKnRvWYc8wjHKnVBzc3UOGQCPGA1HVu1V1oqpOHDRoUN6EMwzDqHQKrSzed01LuP9udsebgQN85w0FNrnjQwPGDcMwjAJSaGXxOPAV9/VXgAW+8fNFpK+IjMBxZC91TVafiMgRIiLAxb7PGIZhGAUiydDZB4BjgIEi0gzMAGYD80XkEuBd4BwAVV0jIvOBN4FdwBWq6lXhu5w9obNPuz+GYRhGAbG2qoZhGEYn1lbVMAzDyBpTFoZhGEZaTFkYhmEYaTFlYRiGYaTFenD7aFzRwpxn32bT1laG1NUybeooy7w2DMPAlEUnjStamP7oqs6+2S1bW5n+6CoAUxiGYVQ8ZoZymfPs252KwsOaFBmGYTiYsnAJa0aUeJMiwzCMMsCUhUtYM6LEmxQZhmGUAaYsXKxJkWEYRjjm4HbxnNgWDWUYhtEdUxY+rEmRYRhGMGaGMgzDMNJiysIwDMNIiykLwzAMIy2mLAzDMIy0mLIwDMMw0tJjO+WJyBbgz3m63EDggzxdK5+YXPEpRZmgNOUqRZmgNOUqRZkgN7kOVNVBqYM9VlnkExFZFtRmsNiYXPEpRZmgNOUqRZmgNOUqRZkgGbnMDGUYhmGkxZSFYRiGkRZTFvG4u9gChGByxacUZYLSlKsUZYLSlKsUZYIE5DKfhWEYhpEW21kYhmEYaTFlYRiGYaSlIpWFiBwgIi+IyFsiskZEvuWOPyQiTe7PRhFpcseHi0ir79hdvmtNEJFVIrJeRG4TEclBrhoRWSoiK125bnLH9xOR50Rknfvvvr7PTHfv/baITM23XBEyzRGRtSLyhog8JiJ17nixv6uZItLiu//Jvs8k+l2lkauoz5Z7vSoRWSEiv3XfF+25ipCpqM9VhFxFfa5CZCrsM6WqFfcDDAYOd1/vDfwRODTlnP8EbnRfDwdWh1xrKfBFQICngZNykEuA/u7rauA14AjgR8B17vh1wA/d14cCK4G+wAjgHaAqn3JFyHQC0Nsd/6FPpmJ/VzOBawLOT/y7ipKr2M+We73/AO4Hfuu+L9pzFSFTUZ+rCLmK+lwFyVToZ6oidxaq+p6qvu6+/gR4C+hsZOFq23OBB6KuIyKDgX1U9VV1/ifuAxpykEtVdZv7ttr9UeAM4F53/F7fPc4AHlTVHaq6AVgPTMqnXGEyqepCVd3lji8BhkZdp4DfVRiJf1dx5CrWsyUiQ4FTgP/2DRftuQqTqdjPVZhcERTtu/IdK8gzVZHKwo+IDAfG46wAPY4C3lfVdb6xEe4W8HcicpQ7Vg80+85pxqd0spSnyt1ObgaeU9XXgL9X1ffAUXTA3/nu/5eA++dVrhCZ/HwNZ5XiUczvCuBK14wx12daKch3lUYuKN6z9VPgO8Bu31hRn6sQmfwU5bmKkKuYz1WYTFCgZ6qilYWI9AceAa5S1b/5Dl1AVy39HjBMVcfjbgVFZB+crVwqOcUiq2qHqo7DWVFNEpExUb9CyP3zKleUTCLyXWAX8Gt3qNjf1Z3AZ4Fxriz/6Ykacv9C/x8W/NkSkVOBzaq6PO5HQu5dMJmK9VxFyFW05yrG/19BnqmKbasqItU4iuLXqvqob7w3cBYwwRtT1R3ADvf1chF5BzgIRzP7t8lDgU35kE9Vt4rIYuBE4H0RGayq77lbyc3uac3AAQH3T0SuFJlWi8hXgFOBf3K3tUX/rlT1x964iPwC+K37tqDfVapcON9XsZ6tycDprlO2BthHRP6H4j5XgTKp6kVFfq5C5fJOKMJzFfVdFe6Ziuvc6Ek/OBr2PuCnAcdOBH6XMjaIPU6rzwAtwH7u+z/gOFY9h9HJOcg1CKhzX9cCv8f5o5lDV0fkj9zXo+nqXPuTT868yBUh04nAm8CgEvuuBvvOuRrHnlyQ7ypKrmI/W777HcMep23RnqsImYr6XEXIVdTnKkimQj9TOX+h5fgDHImz/XoDaHJ/TnaPzQMuSzn/bGCN+1C8DpzmOzYRWI0TBXEHblZ8lnIdBqxw5VrNnuiG/YH/Bda5/+7n+8x33Xu/jS+yIV9yRci0HsdW631/d5XId/UrYJU7/njKH3mi31WUXMV+tnzXPIY9E2DRnqsImYr6XEXIVdTnKkimQj9TVu7DMAzDSEtFO7gNwzCMeJiyMAzDMNJiysIwDMNIiykLwzAMIy2mLAzDMIy0mLIwyh4R2Zby/qsickeerr1YRGI1vheRy0Tk4jzcc7yIxKlLFPd6g90qo6+LyN4px56RPRVy7xKRKnf8ShH513zJYJQ/piwMI0+o6l2qel8eLnU9cHseroOrHBqBa3GKBf7GrV7gca6qfg4Yg5PMdY47Phf4Zj5kMHoGpiyMHo2IDBKRR0TkD+7PZHd8koi84hZbe0VERrnjtSLyoFsw7iGcLOyg684WkTfd837sjs0UkWtEZIjs6SXQJCIdInJgmCwp190bOExVV7rv+4vIPeL0IHhDRM52x7eJyA9FZLmILHJ/n8Ui8icROd09pxqnZtAPVfURVf0vnISyX3j30z010XoDfXBrBanqdmCjiEzK9f/A6BlUbG0oo0dRK27jF5f9cCZFgP8CfqKqL4nIMOBZ4BBgLXC0qu4SkeOAH+Bkvl4ObFfVw0TkMJwM2C6IyH7AmcDBqqriNujxUNVNOAXnEJErgC+p6p9F5P4QWfx4GbYeNwAfq+pY93petdN+wGJVvVZEHgO+DxyP01/hXuBxVW3HKYHil+3/Dfh9ngUm4ZR/+I3v0DKciqZLUz9jVB6mLIyeQKs6VV4Bx2eBM+kCHAccKnsagu3jrt4HAPeKyEic1bRnmjkauA1AVd8QkTcC7vc3oA34bxF5kj1F5brg7hz+DWfCDZVFnZ4qHoOBLb73xwHne29U9SP35U7gGff1KmCHqraLyCqc5jexUdWpIlKDU+H1WOA599Bm4OBMrmX0XExZGD2dXsAXVbXVPygitwMvqOqZ4vQ0Wew7HFkDx92NTAL+CWcivxJnkvVffzDwS+B03dMMKVCWFFpxKot2XipEnnbdU6tnN3uqjO52K5FmhKq2icjjOM18PGVR48pjGOazMHo8C3EmcwBEZJz7cgBONU6Ar/rOfxH4Z/fcMTiFAbsgTh+UAar6FHAVrsnJd7wamA9cq6p/jCGLn7eAf4z4zL7dPpElrj9ksPu6N3AyjnnO4yC6msSMCsaUhdHT+SYw0XUOvwlc5o7/CLhFRF4Gqnzn3wn0d81P3yHYXr838Fv3nN/hlKz283+AzwM3+ZzcQyJk6URV1wIDfCGu3wf2FZHVIrISmJLxNxBOP+Bx9/dYiWN2ust3fDKwKI/3M8oYqzprGCWGiFwNfKKqecu1yEKG8cB/qOq/FEsGo7SwnYVhlB534vogishAnEgswwBsZ2EYhmHEwHYWhmEYRlpMWRiGYRhpMWVhGIZhpMWUhWEYhpEWUxaGYRhGWv5/SRkS+ec96oEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train, y_train, marker='o', label='training data')\n",
    "plt.scatter(X_test, y_test, marker='s', label='test data')\n",
    "plt.xlabel('Head size (cm^3)')\n",
    "plt.ylabel('Brain weight (grams)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, on to the more exciting parts, fitting a linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `fit` method, we train the model on the training dataset (the features and targets), so that the model \"learns\" the model coefficients of the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.271117])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_ # slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302.03033196088086"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_ # y-axis intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to make predictions on new data (here: predicting the brain weight based on the head size), we use the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1363.72450435, 1270.18913932, 1506.33204641, 1133.54617127,\n",
       "       1341.76402734, 1471.90018739, 1270.46025632, 1347.45748435,\n",
       "       1187.76957129, 1398.96971437, 1195.90308129, 1270.18913932,\n",
       "       1160.11563728, 1353.42205835, 1361.28445135, 1403.57870337,\n",
       "       1249.04201331, 1301.63871133, 1501.4519404 , 1219.2191433 ,\n",
       "       1220.8458453 , 1331.19046434, 1589.02273144, 1112.39904526,\n",
       "       1429.87705238, 1318.17684834, 1345.83078235, 1134.08840527,\n",
       "       1182.07611429, 1385.14274736, 1194.54749629, 1459.69992239,\n",
       "       1329.83487934, 1430.14816938, 1245.24637531, 1158.21781828,\n",
       "       1273.98477732, 1434.48604138, 1326.58147534, 1098.84319525,\n",
       "       1295.94525433, 1398.96971437, 1360.19998335, 1222.2014303 ,\n",
       "       1369.41796135, 1221.9303133 , 1340.40844234, 1307.87440233,\n",
       "       1316.00791233, 1201.59653829, 1235.48616331, 1441.80620038,\n",
       "       1170.41808328, 1396.25854436, 1384.60051336, 1419.30348937,\n",
       "       1347.99971835, 1259.07334231, 1272.62919232, 1389.75173636,\n",
       "       1346.10189935, 1197.25866629, 1208.6455803 , 1289.43844633,\n",
       "       1192.37856029, 1223.5570153 , 1327.39482634, 1307.06105133,\n",
       "       1224.3703663 , 1356.94657935, 1387.85391736, 1306.24770033])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful quantitative measure of a model's performance is the so-called Mean Squared Error (MSE), which is simply the average value of the SSE cost function that we minimize to fit the linear regression model. The MSE is useful to for comparing different regression models or for tuning their parameters via a grid search and cross-validation:\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} \\big( y^{(i)} - \\widehat{y}^{(i)}  \\big)^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it may be more useful to report the coefficient of determination ($R^2$), which can be understood as a standardized version of the MSE, for better interpretability of the model performance. In other words, $R^2$ is the fraction of response variance that is captured by the model. The $R^2$ value is defined as follows:\n",
    "\n",
    "$$R^2 = 1 - \\frac{SSE}{SST}$$\n",
    "\n",
    "Here, SSE is the sum of squared errors and SST is the total sum of squares $SST = \\sum^{n}_{i=1} \\big( y^{(i)} - \\mu_y \\big)^2$, or in other words, it is simply the variance of the response. Let's quickly show that $R^2$ is indeed just the rescaled version of the MSE:\n",
    "\n",
    "$$R^2 = 1 - \\frac{SSE}{SST}$$\n",
    "\n",
    "$$= 1 - \\frac{\\frac{1}{n} \\sum^{n}_{i=1} \\big( y^{(i)} - \\hat{y}^{(i)}  \\big)^2 }{\\frac{1}{n} \\sum_{i=1}^{n} \\big( y^{(i)} - \\mu_y \\big)^2 }$$\n",
    " \n",
    "$$= 1 - \\frac{MSE}{Var(y)}$$\n",
    "\n",
    "For the training dataset, $R^2$ is bounded between 0 and 1, but it can become negative for the test set. If $R^2$ =1, the model  fits the data perfectly with a\n",
    "corresponding $MSE = 0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this calculation \"manually,\" first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.635\n"
     ]
    }
   ],
   "source": [
    "sum_of_squares = ((y_test - y_pred)**2).sum()\n",
    "res_sum_of_squares = ((y_test - y_test.mean())**2).sum()\n",
    "r2_score = 1 - (sum_of_squares / res_sum_of_squares)\n",
    "print('R2 score: %.3f' % r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the $R^2$ can conveniently be computed via the regressor's `score` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.635\n"
     ]
    }
   ],
   "source": [
    "print('R2 score: %.3f' % lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's visualize how the regression fit looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.271117])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302.03033196088086"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_pred = X_train.min() * lr.coef_ + lr.intercept_\n",
    "max_pred = X_train.max() * lr.coef_ + lr.intercept_\n",
    "\n",
    "plt.scatter(X_train, y_train, marker='o')\n",
    "plt.plot([X_train.min(), X_train.max()],\n",
    "         [min_pred, max_pred],\n",
    "         color='darkorange',\n",
    "         linewidth=4)\n",
    "plt.xlabel('Head size (cm^3)')\n",
    "plt.ylabel('Brain weight (grams)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that other performance metrics are available from sckit-learn's `metrics` module, http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics. For instance, we can do the following to compute the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5068.2151308071625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that the MSE value looks very large; this is because we haven't normalized the data; we will talk about that later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='height:100px;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Introduction to Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's start by taking a quick look at the structure of the dataset, which is shown in the following screenshot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/dataset_iris_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the dataset is organized in 5 columns, which are separated by commas. The first four columns contain the features (several flower leaf dimensions in cm), and the last column contains the class labels. Using the convenient pandas `read_csv` function, we read the dataset into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width           class\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_iris.txt',\n",
    "                 encoding='utf-8',\n",
    "                 comment='#',\n",
    "                 sep=',')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we assign the features to an NumPy array `X` and the class labels to a NumPy array `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (150, 4)\n",
      "y shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :4].values\n",
    "y = df['class'].values\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique class labels are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While most scikit-learn classifier objects can take care of the label encoding internally, it's usually recommended/common practice in machine learning to work with numeric (integer) labels for computationally efficiency/compatibility reasons.\n",
    "\n",
    "So, this dataset offers a good opportunity for explaining how we can conveniently use some of scikit-learn's utilities to encode labels, starting with the `LabelEncoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(y)\n",
    "l_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via the `fit` method, the encoder learned a mapping between string and integer class labels. For instance, the first element in the `classes_` array corresponds to label 0, the second entry corresponds to label 1, and so forth. Thus, the mapping in this case would be the following one:\n",
    "\n",
    "- 'Iris-setosa' -> 0\n",
    "- 'Iris-versicolor' -> 1\n",
    "- 'Iris-virginica' -> 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform the class labels stored in array y, we can call the `transform` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_enc = l_encoder.transform(y)\n",
    "np.unique(y_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveniently, there's also a `inverse_transform` method that allows us to transform integer class labels back into their string representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(l_encoder.inverse_transform(y_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn's in-built datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our convenience, scikit-learn comes with many different toy/benchmark datasets built-in, which are useful for learning and debugging purposes: http://scikit-learn.org/stable/datasets/index.html#toy-datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can load the same iris dataset from scikit-learn as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/train splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyways, after this little \"label encoding digression\" let's continue with the main objective, fitting a classifier. To fit a classifier, we need a training dataset (and an independent dataset for testing).\n",
    "\n",
    "Here, we are only focusing on 2 features, sepal length and sepal width, for illustrative purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [0 1 2]\n",
      "Class proportions: [50 50 50]\n"
     ]
    }
   ],
   "source": [
    "X, y = iris.data[:, :2], iris.target\n",
    "# ! We only use 2 features for visual purposes\n",
    "\n",
    "print('Class labels:', np.unique(y))\n",
    "print('Class proportions:', np.bincount(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to split the dataset into 70% training data and 30% test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [0 1 2]\n",
      "Class proportions (training set): [32 40 33]\n",
      "Class proportions (test set): [18 10 17]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "print('Class labels:', np.unique(y_train))\n",
    "print('Class proportions (training set):', np.bincount(y_train))\n",
    "print('Class proportions (test set):', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the discussion about class imbalance and stratification from the lecture? Especially if the dataset is small, random subsampling can skew the class label distributions a lot! Fortunately, it's easy to perform a stratified split by providing the class labels to the `stratify` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [0 1 2]\n",
      "Class proportions (training set): [35 35 35]\n",
      "Class proportions (test set): [15 15 15]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "print('Class labels:', np.unique(y_train))\n",
    "print('Class proportions (training set):', np.bincount(y_train))\n",
    "print('Class proportions (test set):', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to fit a logistic regression model to predict whether an unseen flower is either a Iris setosa, versicolor, or virginica flower. Note that logistic regression is actually a binary classifier, meaning that it can only predict binary outcomes (0 or 1). There are multiple ways for applying logistic regression to multi-class problems. One of these is called OvR (one-vs-rest). \n",
    "\n",
    "in OvR, we fit 3 different logistic regression classifiers:\n",
    "1. Setosa vs versicolor & virginica\n",
    "2. Versicolor vs setosa & virginica\n",
    "3. Virginica vs setosa & versicolor\n",
    "\n",
    "Then, during prediction time, we let all of these classifiers make a prediction, and for the final prediction, we take the one classifier that outputs the highest probability for the *one* class it was trained on against the *rest*.\n",
    "\n",
    "Another method is OvO (one-vs-one). Here, we train $K (K − 1) / 2$ binary logistic regression classifiers, where K is the number of classes (here: $3 (3-1)/2 = 3$). Then, to make a prediction, all of the binary classifiers are used, and the class with the highest number of votes gets selected.\n",
    "\n",
    "The third strategy, and probably the most efficient and natural one when it comes to logistic regression, is the so-called multinomial regression model (or also known as softmax regression), which is a generalization of logistic regression for more than two classes. In a nutshell, the modification is depicted in the following figure:\n",
    "\n",
    "![](images/softmax.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go over the mathematical details due to timing constraints, but if you are interested, I have a write-up at http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/.\n",
    "\n",
    "In any case, this was just the long way of explaining where the term \"multinomial\" in the following code example comes from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='newton-cg', \n",
    "                        multi_class='multinomial', \n",
    "                        random_state=1)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print('Test accuracy %.2f' % lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet above should look familiar to you. One of the nice things about scikit-learn is that the API is not only convenient but also consistent. Hence, the procedure for fitting and evaluating a classifier is exactly is equivalent to the approach we've used earlier to fit the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to use a handy tool that I implemented in mlxtend to visualize the decision regions of classifiers in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_decision_regions\n\u001b[1;32m      3\u001b[0m plot_decision_regions\n\u001b[1;32m      5\u001b[0m plot_decision_regions(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, clf\u001b[38;5;241m=\u001b[39mlr, X_highlight\u001b[38;5;241m=\u001b[39mX_test)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "plot_decision_regions\n",
    "\n",
    "plot_decision_regions(X=X, y=y, clf=lr, X_highlight=X_test)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.xlabel('sepal width [cm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both training and test data points are shown, where the test data points are circled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to use a K-nearest neighbor classifier, which is a \"lazy\" learner as discussed in the lecture slides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "kn.fit(X_train, y_train)\n",
    "print('Test accuracy %.2f' % kn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_decision_regions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_decision_regions\u001b[49m(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, clf\u001b[38;5;241m=\u001b[39mkn, X_highlight\u001b[38;5;241m=\u001b[39mX_test)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msepal length [cm]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msepal width [cm]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_decision_regions' is not defined"
     ]
    }
   ],
   "source": [
    "plot_decision_regions(X=X, y=y, clf=kn, X_highlight=X_test)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.xlabel('sepal width [cm]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which of the two models above would you prefer if you had to choose? Why?\n",
    "- What would be possible ways to resolve ties in KNN when `n_neighbors` is an even number?\n",
    "- Can you find the right spot in the scikit-learn documentation to read about how scikit-learn handles this?\n",
    "- Train & evaluate the Logistic Regression and KNN algorithms on the 4-dimensional iris datasets. \n",
    "  - What performance do you observe? \n",
    "  - Why is it different vs. using only 2 dimensions? \n",
    "  - Would adding more dimensions help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='height:100px;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Feature Preprocessing & scikit-learn Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features: nominal vs ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are working with categorical features, we need to be careful to encode them correctly. For instance if a feature is nominal (no order implied), we do not want to simply replace feature values by different integers as machine learning algorithms usually assume the following relationship: 0 < 1 < 2 < 3 ... etc. In the next sections, we will look over some approaches on how to accomplish that. But first, let's start with a simple toy data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>prize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  prize\n",
       "0  green    M   10.0\n",
       "1    red    L   13.5\n",
       "2   blue   XL   15.3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([['green', 'M', 10.0],\n",
    "                   ['red', 'L', 13.5],\n",
    "                   ['blue', 'XL', 15.3]])\n",
    "\n",
    "df.columns = ['color', 'size', 'prize']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One out of many approaches includes using scikit-learn's `DictVectorizer`, which requires a Python dictionary as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'color': 'green', 'size': 'M', 'prize': 10.0},\n",
       " 1: {'color': 'red', 'size': 'L', 'prize': 13.5},\n",
       " 2: {'color': 'blue', 'size': 'XL', 'prize': 15.3}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_as_dict = df.transpose().to_dict()\n",
    "data_as_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of transformer classes in scikit-learn is similar to how we use classifiers or regressors. First, we call a `fit` method on the dataset, and then we invoke a `transform` method (instead of `predict`) to transform a dataset. Note that `.fit_transform(X)` is a shortcut for `.fit(X).transform(X)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1. ,  0. , 10. ,  0. ,  1. ,  0. ],\n",
       "       [ 0. ,  0. ,  1. , 13.5,  1. ,  0. ,  0. ],\n",
       "       [ 1. ,  0. ,  0. , 15.3,  0. ,  0. ,  1. ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dvec = DictVectorizer(sparse=False)\n",
    "\n",
    "X = dvec.fit_transform(data_as_dict.values())\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `DictVectorizer` automatically converts string variables into a one-hot encoded format. However, if you are interested in just converting integers into a one-hot encoded format, also have a look at scikit-learn's `OneHotEncoder` class (http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).\n",
    "\n",
    "However, in practice, we may want to encode ordinal variables in a different way as they have an internal order (the values needed to be decided by the researcher and varies from case to case). For instance, it's super easy to achieve such an encoding using our pandas DataFrame via the map function and a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>prize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  prize\n",
       "0  green     1   10.0\n",
       "1    red     2   13.5\n",
       "2   blue     3   15.3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_mapping = {'XL': 3, 'L': 2, 'M': 1}\n",
    "\n",
    "df_new = df.copy()\n",
    "df_new['size'] = df_new['size'].map(size_mapping)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color     object\n",
       "size       int64\n",
       "prize    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1. ,  0. , 10. ,  1. ],\n",
       "       [ 0. ,  0. ,  1. , 13.5,  2. ],\n",
       "       [ 1. ,  0. ,  0. , 15.3,  3. ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dvec.fit_transform(df_new.transpose().to_dict().values())\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that NumPy arrays only have a single type, hence, the last column contains floats, not integers as in the DataFrame `df_new`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data normalization can be performed quite easily with scikit-learn as well, using the transformer interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature\n",
       "0      1.0\n",
       "1      2.0\n",
       "2      3.0\n",
       "3      4.0\n",
       "4      5.0\n",
       "5      6.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([1., 2., 3., 4., 5., 6.], columns=['feature'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>minmax</th>\n",
       "      <th>z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.46385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.87831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.29277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.29277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.87831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.46385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  minmax  z-score\n",
       "0      1.0     0.0 -1.46385\n",
       "1      2.0     0.2 -0.87831\n",
       "2      3.0     0.4 -0.29277\n",
       "3      4.0     0.6  0.29277\n",
       "4      5.0     0.8  0.87831\n",
       "5      6.0     1.0  1.46385"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mmxsc = MinMaxScaler()\n",
    "stdsc = StandardScaler()\n",
    "\n",
    "X = df['feature'].values[:, np.newaxis]\n",
    "\n",
    "df['minmax'] = mmxsc.fit_transform(X)\n",
    "df['z-score'] = stdsc.fit_transform(X)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, it's usually recommended to normalize your input data. The only algorithms that is scale-invariant and comes to mind are tree-based algorithms (decision trees, random forests, etc.). \n",
    "\n",
    "\n",
    "Some examples of algorithms where feature scaling matters are:\n",
    "\n",
    "- k-nearest neighbors with an Euclidean distance measure if want all features to contribute equally\n",
    "- k-means (see k-nearest neighbors)\n",
    "- logistic regression, SVMs, perceptrons, neural networks etc. if you are using gradient descent/ascent-based optimization, otherwise some weights will update much faster than others\n",
    "- linear discriminant analysis, principal component analysis, kernel principal component analysis since you want to find directions of maximizing the variance (under the constraints that those directions/eigenvectors/principal components are orthogonal); you want to have features on the same scale since you'd emphasize variables on \"larger measurement scales\" more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important point to highlight is that we want to retrieve the normalization parameters from the training set and apply these to the test set (**don't refit a transformer on the test set!**), otherwise, funny things might happen.\n",
    "\n",
    "\n",
    "Let me give a hands-on example why this is important!\n",
    "\n",
    "Let's imagine we have a simple training set consisting of 3 samples with 1 feature column (let's call the feature column length in cm\"):\n",
    "\n",
    "- sample1: 10 cm -> class 2\n",
    "- sample2: 20 cm -> class 2\n",
    "- sample3: 30 cm -> class 1\n",
    "\n",
    "Given the data above, we compute the following parameters:\n",
    "\n",
    "- mean: 20\n",
    "- standard deviation: 8.2\n",
    "\n",
    "If we use these parameters to standardize the same dataset, we get the following values:\n",
    "\n",
    "- sample1: -1.21 -> class 2\n",
    "- sample2: 0 -> class 2\n",
    "- sample3: 1.21 -> class 1\n",
    "\n",
    "Now, let's say our model has learned the following hypotheses: It classifies samples with a standardized length value < 0.6 as class 2 (class 1 otherwise). So far so good. Now, let’s imagine we have 3 new unlabeled data points that you want to classify.\n",
    "\n",
    "- sample4: 5 cm -> class ?\n",
    "- sample5: 6 cm -> class ?\n",
    "- sample6: 7 cm -> class ?\n",
    "\n",
    "If we look at the \"unstandardized \"length in cm\" values in our training dataset, it is intuitive to say that all of these samples are likely belonging to class 2. However, if we standardize these by re-computing the *standard deviation* and and *mean* from the new data, we would get similar values as before (i.e., properties of a standard normal distribution) in the training set and our classifier would (probably incorrectly) assign the \"class 2\" label to the samples 4 and 5.\n",
    "\n",
    "- sample5: -1.21 -> class 2\n",
    "- sample6: 0 -> class 2\n",
    "- sample7: 1.21 -> class 1\n",
    "\n",
    "However, if we use the parameters from your \"training set standardization, we will get the following standardized values\n",
    "\n",
    "- sample5: -18.37\n",
    "- sample6: -17.15 \n",
    "- sample7: -15.92\n",
    "\n",
    "Note that these values are more negative than the value of `sample1` in the original training set, which makes much more sense now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn's pipelines are a super convenient tools that allow us to group multiple, different preprocessing steps together. For instance, in this simple example, we will be creating a pipelines that bundles a `StandardScaler` with a `LogisticRegression` classifier.\n",
    "\n",
    "Note that the a `Pipeline` has a API that is similar to the classifier's API. If we call `fit` using a training dataset, it will fit the `StandardScaler` within the pipeline, transform the training dataset (here: standardizing it), and provide it to the classifier's fit method. Then, upon calling `predict` on the pipeline (or `score`), the test data will automatically be transformed via the `StandardScaler` and passed on to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "lr = LogisticRegression(solver='newton-cg',\n",
    "                        multi_class='multinomial',\n",
    "                        random_state=1)\n",
    "\n",
    "lr_pipe = make_pipeline(StandardScaler(), lr)\n",
    "\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "lr_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is just a simple example, pipelines are a super important concept in scikit-learn, because it not only allows us to perform operations more conveniently by grouping them, but also enforces doing them the \"right\" way, i.e., using training set parameters (e.g., the mean and standard deviation from standardization) on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in case we want to access the individual elements within the pipeline, we can do so via the `named_steps` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standardscaler': StandardScaler(),\n",
       " 'logisticregression': LogisticRegression(multi_class='multinomial', random_state=1,\n",
       "                    solver='newton-cg')}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.92257899,  1.04365194, -1.36204734, -1.33302226],\n",
       "       [-1.17919036, -0.09310588, -1.36204734, -1.33302226],\n",
       "       [-1.43580174,  0.36159725, -1.42034941, -1.33302226],\n",
       "       [-1.56410743,  0.13424568, -1.30374528, -1.33302226],\n",
       "       [-1.05088468,  1.2710035 , -1.36204734, -1.33302226]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe.named_steps['standardscaler'].transform(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why is it important that we scale test and training sets separately?\n",
    "- Fit a KNN classifier to the standardized Iris dataset. Do you notice difference in the predictive performance of the model compared to the non-standardized one? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='height:100px;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Dimensionality Reduction: Feature Selection & Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will introduce some basic feature selection and feature extraction techniques that can be used for dimensionality reduction. As always, we start by loading a dataset and splitting it into a training and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature elimination fits an a regression model iteratively. It starts with the full feature subset (the 4 Iris features) and removes the feature with the smallest regression coefficient in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rfe = RFE(lr, step=1)\n",
    "\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it's finished, we can access the number of features that resulted in the best model via the `n_features_` attribute. Also, if we want to know which features were selected, we can look at the array stored under the `ranking_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 2\n",
      "Feature ranking [3 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "print('Number of features:', rfe.n_features_)\n",
    "print('Feature ranking', rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower the ranking number the better; ranking values of 1 correspond to the selected features. In this case, this would be the petal length and petal width of the iris flowers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential feature selection algorithms are a family of greedy search algorithms that are used to reduce an initial d-dimensional feature space to a k-dimensional feature subspace where k < d. The motivation behind feature selection algorithms is to automatically select a subset of features that is most relevant to the problem. The goal of feature selection is two-fold: We want to improve the computational efficiency and reduce the generalization error of the model by removing irrelevant features or noise. A wrapper approach such as sequential feature selection is especially useful if embedded feature selection -- for example, a regularization penalty like LASSO -- is not applicable.\n",
    "\n",
    "In a nutshell, SFAs remove or add one feature at the time based on the classifier performance until a feature subset of the desired size k is reached.\n",
    "\n",
    "\n",
    "How is this different from Recursive Feature Elimination (RFE) -- e.g., as implemented in `sklearn.feature_selection.RFECV`? `RFECV` is computationally less complex using the feature weight coefficients (e.g., linear models) or feature importance (tree-based algorithms) to eliminate features recursively, whereas SFSs eliminate (or add) features based on a user-defined classifier/regression performance metric.\n",
    "\n",
    "(Please see http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/ for more info).\n",
    "\n",
    "Note that sequential feature selection algorithms are currently not implemented in scikit-learn; however, we are in the process of porting my mlxtend implementation over to scikit-learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we will let the SFS run over all 4 features to suggest a feature subset for each feature size via forward selection. Once it's completed, we can access the scores for each subset via the `subsets_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequentialFeatureSelector \u001b[38;5;28;01mas\u001b[39;00m SFS\n\u001b[1;32m      3\u001b[0m sfs \u001b[38;5;241m=\u001b[39m SFS(lr, \n\u001b[1;32m      4\u001b[0m           k_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, \n\u001b[1;32m      5\u001b[0m           forward\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      6\u001b[0m           scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m           cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      9\u001b[0m sfs\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs = SFS(lr, \n",
    "          k_features=4, \n",
    "          forward=True, \n",
    "          scoring='accuracy',\n",
    "          cv=5)\n",
    "\n",
    "sfs.fit(X_train, y_train)\n",
    "sfs.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that both RFECV and SFS are performing cross-validation internally to estimate the performance during the selection. We haven't talked about cross-validation, yet, but will do so in section 5. So, for now, only the \"avg_score\" is of interest. In this case, the results indicate the using more features improves the performance. \n",
    "\n",
    "In addition, we can use a helper utility to visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_sequential_feature_selection \u001b[38;5;28;01mas\u001b[39;00m plot_sfs\n\u001b[1;32m      4\u001b[0m fig1 \u001b[38;5;241m=\u001b[39m plot_sfs(sfs\u001b[38;5;241m.\u001b[39mget_metric_dict(), kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_err\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim([\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "\n",
    "fig1 = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.ylim([0.8, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb for selecting feature subsets is to select the smallest feature subsets that is within 1 standard error of the best performing one, which would be the feature subset with `'feature_idx': (2, 3)`, i.e., petal length and petal width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis is a technique that compresses data onto a smaller-dimensional subspace while retaining most of its variance or spread (aka information). We won't go into the mathematical details of PCA here,  but I have written a post about it if you are interested: https://sebastianraschka.com/Articles/2015_pca_in_3_steps.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we specify n_components=4 and run this algorithm on our 4-feature iris dataset, it actually wouldn't reduce the dimensionality. However, this is still a useful approach since we can look at the variance-explained ratios of the individual components, which give us a clue in terms of how many components we should keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_exp = pca.explained_variance_ratio_\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "idx = [i for i in range(len(var_exp))]\n",
    "labels = [str(i + 1) for i in idx]\n",
    "\n",
    "plt.bar(range(4),\n",
    "        var_exp,\n",
    "        alpha=0.5,\n",
    "        align='center',\n",
    "        label='individual explained variance')\n",
    "\n",
    "plt.step(range(4),\n",
    "         cum_var_exp,\n",
    "         where='mid', \n",
    "         label='cumulative explained variance')\n",
    "\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.xticks(idx, labels)\n",
    "plt.legend(loc='center right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative distribution plot above indicates that approx. 95% of the variance is explained by the first two components. Thus, a dimensionality reduction down to 2 dimensions would make sense in this case. In the following plot, the transformed iris data is visualized on the two new component axes. Note that PCA is a unsupervised technique and the class labels are only shown for illustrative purposes (or in other words, PCA does not use class labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnKElEQVR4nO3df7xcdX3n8dc7ITHEJHWBKD9CEggKAdSgQaWyKC1dabS4QhXprQuLNA+MrbixrbaxC/Q+2LVb9aFo/JE2jSzeQm0rGxSKoiBYKoQg4TcRxARuvCwpXZpAgAv3fvaPM5NMbubHmZkzc87MfT8fj3nczJmZcz6D5n7y/X4/5/NVRGBmZlY0U/IOwMzMrBonKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzK6TcEpSkGZI2SLpH0gOSLs0rFjMzKx7ldR+UJAGvjIhnJU0D/hm4KCJuzyUgMzMrlP3yunAkmfHZ0tNppUfdbHnQQQfFwoULOxyZmZl101133fWvETF34vHcEhSApKnAXcBRwOqIuKPe+xcuXMjGjRu7EpuZmXWHpK3VjudaJBERYxGxBJgHvEXS8RPfI2m5pI2SNm7fvr3rMZqZWT4KUcUXEc8APwJOr/LamohYGhFL587dZwRoZmZ9Ks8qvrmSXlX68/7AacDDecVjZmbFkuca1CHAFaV1qCnAtyLiuznGY2ZmBZJnFd+9wAl5Xd/MzIqtEGtQZmb9YmTnCIsuX8STzz6Zdyg9zwnKzCxDg7cOsuWZLQzeMph3KD3PCcrMLCMjO0dYt2kd4zHOuk3rPIpqkxOUmVlGBm8dZDzGARiLMY+i2uQEZWaWgfLoaXRsFIDRsVGPotrkBGVmloHK0VOZR1HtcYJq0dAQLFwIU6YkP4eG8o7IzPJ07eZrd4+eykbHRlm/eX1OEfW+XJvF9qqhIVi+HHbtSp5v3Zo8BxgYyC8uM8vP8MrhvEPoOx5BtWDVqj3JqWzXruS4mZllwwmqBY8/3txxMzNrnhNUC+bPb+64mZk1zwmqBZddBjNn7n1s5szkuJmZZcMJqgUDA7BmDSxYAFLyc80aF0iYmWXJVXwtGhhwQjIz6ySPoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzM2jSyc4RFly/iyWefzDuUvuIEZWbWpsFbB9nyzBYGbxnMO5S+kluCknS4pJslPSTpAUkX5RWLmVmrRnaOsG7TOsZjnHWb1nkUlaE8R1AvA5+IiMXA24CPSjo2x3jMzJo2eOsg4zEOwFiMeRSVodwSVESMRMRPS3/eCTwEHJZXPGZmzSqPnkbHRgEYHRv1KCpDhViDkrQQOAG4o8pryyVtlLRx+/btXY/NzKyWytFTmUdR2ck9QUmaBfwj8PGI2DHx9YhYExFLI2Lp3Llzux+gmVkN126+dvfoqWx0bJT1m9fnFFF/2S/Pi0uaRpKchiLi23nGYmbWrOGVw3mH0NfyrOITsBZ4KCI+n1ccWRkagoULYcqU5OfQUN4RmZn1tjyn+N4OfAj4NUmbSo9lOcbTsqEhWL4ctm6FiOTn8uVOUmZm7VBE5B1DakuXLo2NGzfmHcY+Fi5MktJECxbAli3djsbMrLdIuisilk48nnuRRD94/PHmjpuZWWNOUBmYP7+542Zm1pgTVAYuuwxmztz72MyZyXEzM2uNE1QGBgZgzZpkzUlKfq5Zkxw3M7PW5HofVD8ZGHBCMjPLkkdQZmZWSE5QZmZWSE5QZmZWSE5QZmZWSE5QZmZWSE5QZmZWSE5QZmZWSE5QZmZWSE5QGWi0F5T3ijIza547SbSpvBfUrl3J8/JeUJB0lmj0upmZVVdzBCXp9ZJul/SEpDWS/kPFaxu6E17xrVq1J/mU7dqVHE/zeiWPtMzM9qg3xfdV4BLg9cDPgH+WtKj02rQOx9UzGu0FlXavKO/Ka2a2t3oJalZE3BARz0TEZ4HfB26Q9Dagd7bh7bBGe0Gl3SuqmZGWmdlkUC9BSdKvlJ9ExM3AWcCVwIJOB9YrGu0FlXavKO/Ka2a2t3oJ6i+AxZUHIuJe4NeBb3cyqF7SaC+otHtFeVdeM7O9KaJ3ZuuWLl0aGzduzDuMjphY7QfJSMsbH5pZv5N0V0QsnXjc90EVhHflNTPbm++DKhDvymtmtkfDEZSkt6c5ZmZmlqU0U3xfSnnMzMwsMzWn+CSdBPwqMFfSyoqX5gBTOx2YmVmlkZ0jnLzuZG47/zYOnnVw3uFYF9QbQU0HZpEksdkVjx3Ab3c+NDOzPQZvHWTLM1sYvGVwn9dGdo6w6PJFPPnskzlEZp1SM0FFxC0RcSnwtoi4tOLx+Yh4pIsx9hz31DPL1sjOEdZtWsd4jLNu07p9ElG95GW9K80a1CtKzWK/L+mm8qPjkRVAK4nGPfXM0mlm1DN46yDjMQ7AWIztlYgaJS/rXWkS1N8DdwOfBv6o4tHXWk007qlnlk7aUU85AY2OjQIwOja6VyKql7xa5SnDYkiToF6OiK9GxIaIuKv8yOLikv5G0lOS7s/ifFlqNdFs3Vr9uHvqme3RzKinMgGVlRNRo+TVKk8ZFkOaBPUdSSskHSLpgPIjo+t/Azg9o3NlqpXmrUNDSReIatxTz/rOnDnJ/+EnPubMafjRZkY9126+dncCKhsdG2X95vV1k1erPGVYHA178Un6RZXDERFHZhKAtBD4bkQc3+i93ezFt3Bh9dHQggWwZcue50NDyajq8ceTtaqxsX0/I8GVV7pLhPWZWv8ag2RevIaRnSMcefmRvPDyC7uP7b/f/jx20WNNl4/P+/w8tu3cts/xw2YfxvDK4abOVbbiuhWsvXsto2OjTJ86nQtOuIDV717d0rksnVq9+HJvFtsoQUlaDiwHmD9//pu31ppDy1ia5q3V3lNLD/XkNUunxQRVmQDKipIIskyell7LzWIlzZT0aUlrSs9fK+k9nQiymohYExFLI2Lp3Llzu3XZVM1bq61TVbPAu2eZ7VZvyi5vnZgytNalmeL7O+Au4L9ExPGS9gd+EhFLMgmgoFN8aUyZ0nhk5C0zrGVz5sDOnfsenz0bduzofjwTtTiCKrJOTBlaY7VGUGm6mS+KiLMlnQMQEc9L9f6fOXnMn1+7ag/gwAPhi190crIWVUtO9Y5b25yEiiVNFd9oadQUAJIWAS9mcXFJVwE/AY6WNCzpw1mct1uqbedeadYsJyfrY7NnN3e8QHyfU29Ik6AuBm4ADpc0BPwQ+OMsLh4R50TEIRExLSLmRcTaLM7bLeV1qlp875P1tR07kqm8iY8iTD9WUZmUfJ9Tb2iYoCLiRuBM4DzgKmBpRPyos2H1joGB2kUQvvfJrDjKSelTN37K9zn1iLRbvs8A/h9JJ/NjJZ3SuZB6T7Wpvpkzk+Nmk1YbN/JmrfLm22/e983MWyNZZ6QpM/8L4DZgFXv68P1hh+PqKWlK0s2a1sNrPEChijwmdq6o1RrJa1PFkmYE9Z+BoyPi3RHxW6XHGR2Oq+cMDCQdJsbHk59OTta2HlvjKaqJ/fomqhxFNbs25YTWWWkS1GPAtE4HYmYdUqCptjxUu/m2Uvkm4VZ68LnYorPSJKhdwCZJX5d0efnR6cD6kTcytFwUaKotD9U6VwAc/MqDiYuDuDgYXjnc9LYdbirbeWkS1LXAIPAvJB0lyg9rgjcyNMvH8Mph4uLgI0s/wvSp04Gk99+Zi8/c/Z5Wtu3oxD5Utrc0ZeZXkJSXlxPT35aO9b0sRzzeyNAmnQIVeTSz6WFZvaTTqX2obG9pqvjeCTwCrAa+AvxsMpSZZz3iaWV/KbOeVqAij0YJqNkGto3O5+KJbKRpFnsX8DsRsbn0/HXAVRHx5i7Et5ci7geV1/nMUuvDpq7NyroJbKPzrbhuBV+/6+tc+OYLc99CpBe0vB+UpHsj4g2NjnVDNxNUrU7lUlJK3qw0+0uZdUTRu6J3WaeTR+WeUt5LKp2W94MCNkpaK+mdpcdfMQmKJGq1KWrUvqjWupVv5rXcFGiqrSyvKbBNI5v46savdrTyzsUT2UmToD4CPAB8DLgIeBC4sJNBFUEr7YsarVv5Zl6zRF73D/3uNb+7+8+dSB4unshWmiq+F4EvA5cC/x1YXTrW19KMeCaOli66yJV6VkAFu1E3r/uHNo1s4oHtD+x+3onkkaYa0AUU6aWp4ns38HPgiySJ6lFJv9npwIqg3oin2mjp6aern6depV6jUnbf3GttK9iNunlNgVWOnsqyvn6aakB3n0gvTZHEw8B7IuLR0vNFwHURcUwX4ttLUbZ8HxqCc8+FsbF0769VqVetcEJKEt6CBbBsGVxxhQsrrE0FquKrLCAo60YhwcjOEQ79/KFVX+vmdu4uoKiunSKJp8rJqeQx4KnMIusx5aSSNjnVW7eqdvNu+ffF1q3wta95ytC6pEvTgK3cEJvFdNjgrYO7u0iUTZ86nRVLV3R1m3cXUDQnTYJ6QNL1ks6TdC7wHeBOSWdKOrPRh/tNtaRS6cAD01fqNbpJt9Y/bn1zr2WuS9OArdwQm8V0WLPX7QQXUDQvzRTfujovR0Scn21ItRVhiq/W/VHQ/PRbrZt3G/HNvdaUNFN8BZoGLMt6OmzFdStYe/daRsdGmT51OheccEFXb6KtvH5ZHnEUUctTfBHxX+s8upaciqLWfVBTpza/NlStlH2iib83vFOvNa1APfGakeV0WBFGL0UYxfWaNCOoI4A/ABYC+5WP57FpYRFGUFl3hBgaSqYNt27dUyBRed5zz4Xrr0+m9ebPT5KTCyQscwUbQWVdTOHRS7G1UyTxf4AtwJeAz1U8JqWsO0KUS9kj4Mor9z3vV77im3tt8mm2mKIRj146o9P3dKUZQd0REW/tyNWbVIQRlFlfKli/vqybu1pnZNXXsJ1msb8DvBb4PrC7g0RE/LTlaFrU6wmqPJ3n6Toz63VZFrG0M8X3euD3gM+wZ3rvsy1F0YfSdnrwjrpm1k+6cU9X2k4Sb4iI0bpv7IKijaCaKZjwflDWMwo23WfFk3URSzsjqHuAVzV9xUmgmW3cvaOu9YyC9e6z4sm6iKWWNAnqNcDDkr4n6dryI9MoelQzSafV/aXMzIqmW1WR+zV+CxdnesUeNrHI4YADqncwP+CAfY9ddln16cBGN926sMLMiqZblZRpOkncAjwMzC49Hiodm1SqFTns3JkUR0y0c+e+xQ+t3D/lwgprW5tNYEdmwaKPwZOzOhxn+XreK8kqpNkP6gPABuD9wAeAOyT9dhYXl3S6pM2SHpX0qSzO2SnV1ptGa5SNjI5WX4dqdkfdZta4zKpqcz1p8B2w5VUweEp2IdW9nvdKsgppqvjuAX4jIp4qPZ8L/CAi3tjWhaWpwM+A3wCGgTuBcyLiwVqfybOKr16T2GqkJBF14ppZnNsmiVZaGJWq+EZmwZEXwQvTYP+X4LG/fiUHP/lsZ+LEeyVNZu1U8U0pJ6eSp1N+rpG3AI9GxGOlEvargfdmcN621LqvqV6T2GqqrUM1y4UVlosdOyCCwas/wviMZA+lsRnTGVx7bkcv672SbKI0ieaGUgXfeZLOA64D/imDax8GPFHxfLh0LDf11nyqdR6fOTN5fdq0fc9VbR2qWbWu6W7mtpcObDbY7e7f3bqe17h6S5oiiT8Cvg68AXgjsCYi/jiDa1ebe9hnzkHSckkbJW3cvn17Bpetrd6aT60ih698pfrvgVrrUM3IujGt9akO3LdU9z6XDiTETt1XMzEheY2rt9Rcg5J0FPCaiLhtwvFTgG0R8fO2LiydBFwSEe8qPf8TgIj4n7U+0+k1qFbXfLxWZLmqt840e3ZLXSHqNmv9xL7Hd2txa45ONYetbGb66VM+7TWugqq1BlXvPqgvAH9a5fiu0mu/1WZMdwKvLe03tQ34IPA7bZ6zLfPnV29H1GjNp9XPWZ8qUqugFq9XNyl8ok5CbFEn7qspTxuOxzjrNq3juZee22eNy3tBFVu9Kb6FEXHvxIMRsZFk88K2RMTLwO8D3wMeAr4VEQ+0e952tLrm47Ui20uRWgVlOA3XayYWXXzz3m/muqOuNa9egppR57X9s7h4RFwfEa+LiEURkfuv81bXfLxWZMCetZki61CS3H1Db0F+4VcruhiLsb3e40rB4quXoO6U9HsTD0r6MHBX50LKV7M307b7OesjeTVTnT07n+tW2H1D7y2DhaiUq1Z0MZF31C2+emtQHweukTTAnoS0FJgOvK/DcfUc98yz3FRbZ+rkSG5C4cXILFi3BMansHutp1wpl9caT7VmpuAdeXtNmk4SpwLHl54+EBE3dTyqGoq2H1RZM/tCWR9LkxRarKrLNJYWK+1qWXHdCtbevZbRsVGmTZnGeIwzFmOulLPUWt7yvUiKmqC8GaEBjRNUreRUluXfxS4lqGob15VNnzqdC064wJVy1lA7rY6sAW9GaA1FdLfEvNa6VMbrVfXWejpZKVeEdS7rPCeoDLhnngHtJ4VGJeBpOjiU3zNxpDZ7dkeSZK21nrJOVcq5I8Tk4ASVAd8HZcDuJqv7PNImhUZVgGnur+ryPVjDK4eJi4O4ODhs9r6tNGtVytUbATUaHU28AdejqP5VM0FJ2ilpR5XHTkldvh2+mMqdzz/0Idh/fzjwQN8HZZNXZbKqfFSrmqs3Amo0OnLX88nDRRItcuWetaRWG6Syen8f0xQ+dLF6r1X19n1qtCdUtaIMVwv2vraLJCS9WtL88iPb8Iqp1t5Q4N1urUXd7sVXQPVGQI1GR53qem7FlOY+qDOAzwGHAk8BC4CHIuK4zoe3t26OoBqNkNzB3FrW6iinD0ZQ9UZAEdFwdNSprueWr1a6mZcNAm8j2eb9hNKNu+dkHWDRNNobyh3MrWX1btZt93OtnrtL6o2Agqj5WvleKiehySXNFN9LEfE0MEXSlIi4GVjS2bDy1+jeJlfuWctarfZL87l2KwmryPKeo2pl6eVKv3qv2eSUZgT1jKRZwI+BIUlPAS93Nqz8NRohlQshavXfc28+q6vRnlEF2lOqsqpu9btXtxWbR0DWjDQjqPcCz5M0j70B+Dntb1ZYeGlGSLU6mJfXr7ZuTf7xunVr8ryyyMImuUb3KxVkT6mq9xwVJLZOcZeK4miYoCLiOWAusAz4N5KNBZ/udGB5a2ePJ1f4Wb+YjPccuUtFcaSp4rsA+O/ATYCAdwB/HhF/0/nw9lak+6DqcYWfNdSo2q4A1Xg1K+4+8zwHP1vjMzt+ycnrTua282/ryfuSGt2HZZ3Rzn1QfwScEBHnRcS5wJuBT2YdYC+pd38UuDef9YeaFXen1P9ML48+JuOIscjSJKhhoHJyeSfwRGfCKb4060uu8LN+ULOq7pjq7x+ZRU/3yKu2TXwvfo9+kiZBbQPukHSJpIuB24FHJa2UtLKz4RVPmvWlautX556bvKfWqMsmmUadz7u0XUY9NXvr/VX1GAZPm9bTow93qSieNGtQF9d7PSIuzTSiOoqwBtXK+pL79k1yjfrvVcqhjDwL1darZuw3g1e/8tXcccEdPbGO4y4V+fGOuhlpZfdc77g7yaXZCr5SD/2dLKvc9r1siqYwHuOsWLrCu+paXU0XSUj6QunndyRdO/HRwVgLrdb60rJltQsnvOOu9btq61Xl6TKv41ir6nWSuLL087PdCKRXVOsgsWwZXHHFnim8cuFE+f3u22dNkXpuqm/iFFjliGpiPz2ztNKsQb0SeD4i+eeQpKnAKyJiV90PdkARpviqaTSF5zWoSa7ZKb6yHpzqA+/ZZM1r5z6oHwKVk1r7Az/IKrB+0GgKr52uFGa9xtVwlpU0CWpGROy+b7z055l13j/ppLkxt1bfPpsECrLVRbe4K7llJU038+ckvSkifgog6c0kzWOt5LLLqk/h+cZcA+qvJbU6/VdgLsm2rKRJUB8H/l7SL0vPDwHO7lhEPajR1htmLSknrx4rmDDLSqr7oCRNA44maRb7cES81OnAqilqkYRZy9LexNujBRNmabSz5TvAicDC0vtPkERE/O8M4zObnCpHRn043WfWjoZFEpKuJLkX6mSSRHUisE+ma4ak90t6QNK4pLbOZZaLOXOShFLrMWdO3hGa9bw0VXxLgbdHxIqI+IPS42NtXvd+4Ezg1jbPk1qjLTLMmtJoWq5Pdpc1y1OaKb77gYOBkawuGhEPAahLUxoTb5Sd2OnBzMyKJ80I6iDgQUnfy6MXn6TlkjZK2rh9+/aWzuEt2K2wKqcKa+mD+6hGdo6w6PJF7slnTUkzgrqklRNL+gHJyGuiVRGR+o69iFgDrIGkiq+VWNys1Qqr3lRgH1XuVe606558llbDBBURt7Ry4og4rZXPdYKbtZrlp7xTbXmn3T97x5+5J5+lUm+7jX8u/dwpaUfFY6eknrpr0FuwW+YaTbv1wbRcVip787knnzWjZoKKiJNLP2dHxJyKx+yIaKuGVtL7JA0DJwHXSfpeO+drJKtmra4EtN127Eim4Go93PkB2DN6KvfmGx0b9f5QllrdIglJUyTdn/VFI+KaiJgXEa+IiNdExLuyvsZE7TZrLVcCbt2a/P4pVwI6SZnV5s7m1o66Caq0B9Q9kib9ao0rAa0ttW7sraVPpgjd2dzakaaK7xDgAUkbgOfKByPijI5FVUCuBLS29Eu1Xq3egTUa2rqzubUjTYK6tONR9ABXAlrHVBtJFbWDea1E684Z1gE1E5SkGcCFwFHAfcDaiHi5W4EVjfd8sq7yL3yzumtQV5D04bsP+E3gc12JqKC8bbuZWXfVm+I7NiJeDyBpLbChOyEV18CAE5KZWbfUG0Ht3pRwMk/tmWWiT6ryzLqp3gjqjRUdIwTsX3ouINq9WddsUqlV8NBrmxTOnl27is8sYzUTVERM7WYgZpNSr/3CL2JlofWttFu+m1kn+Be+WU1p9oMyMzPrOico60+1WgvN6dDSabevZzYJOEFZf+p2xwN3WDDLnBOUWUF5m3Sb7JygzAqqcpv0fuCEa81yFZ9ZAfXjNumVCXf1u1fnHU5feemllxgeHuaFF17IO5S6ZsyYwbx585g2bVqq9ztBmRVQtW3Se/mXej8m3CIZHh5m9uzZLFy4EBX05u+I4Omnn2Z4eJgjjjgi1Wc8xWf9qdaNrp26ATbD6zW9TXoPVBBWS7iWnRdeeIEDDzywsMkJQBIHHnhgU6M8JyjrTzt2JBsBTnx06sbYDK9XdZv0F55n8OxDqiefglcQNp1wrSVFTk5lzcboBGVWMFW3Sd8P1h9TcaAgySeNqgnXo6i+dMMNN3D00Udz1FFH8ZnPfKbt83kNyqxg9tomvQf+VdxI1YQ7Nsr6zet7el3N9jY2NsZHP/pRbrzxRubNm8eJJ57IGWecwbHHHtvyOZ2gzKyj9kq4VghDQ7BqFTz+OMyfn+wM3u5edxs2bOCoo47iyCOPBOCDH/wg69evbytBeYrPzGwSGRqC5cth69ZkmXTr1uT50FB75922bRuHH3747ufz5s1j27ZtbZ3TCcqs13W7YtF62qpVsGvX3sd27UqOtyMi9jnWbuGGp/jMiizNflHessOa8PjjzR1Pa968eTzxxBO7nw8PD3PooYe2dU6PoMyKrNvl8tb35s9v7nhaJ554Io888gi/+MUvGB0d5eqrr+aMM85o65xOUGZmk8hll8HMmXsfmzkzOd6O/fbbjy9/+cu8613vYvHixXzgAx/guOOOa++c7YVkZma9pFytl3UVH8CyZctYtmxZ+ycqcYIyM5tkBgaySUid5ik+MzMrpFwSlKS/lPSwpHslXSPpVXnEYWZmxZXXCOpG4PiIeAPwM+BPcorDzMwKKpcEFRHfj4iXS09vB+blEYeZmRVXEdagzgf+qdaLkpZL2ihp4/bt27sYlpmZ5aljCUrSDyTdX+Xx3or3rAJeBmp2gYqINRGxNCKWzp07t1PhmplZG84//3xe/epXc/zxx2d2zo4lqIg4LSKOr/JYDyDpXOA9wEBUa+JkZmY947zzzuOGG27I9Jx5VfGdDnwSOCMidjV6v5mZZWTOnD07M1c+KndpbsEpp5zCAQcckFGQibzWoL4MzAZulLRJ0tdyisPMbHKptRtzAXdpzqWTREQclcd1zcysdxShis/MzGwfTlBmZlZITlBmZta2c845h5NOOonNmzczb9481q5d2/Y53c3czGwySbNLcwuuuuqqtj5fjROUmdlk0kO7MXuKr8CGhmDhQpgyJfk5VLPfhplZ//EIqqCGhmD5cthVuo1569bkOfTGRmNmZu3yCKqgVq3ak5zKdu1KjpuZTQZOUAX1+OPNHTcz6zdOUAU1f35zx83M+o0TVEFddhnMnLn3sZkzk+NmZkXzxBNPcOqpp7J48WKOO+44vvjFL7Z9TieoghoYgDVrYMGCpNHwggXJcxdImFkR7bfffnzuc5/joYce4vbbb2f16tU8+OCDbZ3TCarABgZgyxYYH09+OjmZWVZGdo6w6PJFPPnsk5mc75BDDuFNb3oTALNnz2bx4sVs27atrXM6QZmZTUKDtw6y5ZktDN4ymPm5t2zZwt13381b3/rWts7jBGVmNsmM7Bxh3aZ1jMc46zaty2wUBfDss89y1lln8YUvfIE5bW6C6ARllkaHdiE1y8PgrYOMxzgAYzGW2SjqpZde4qyzzmJgYIAzzzyz7fM5QZml0UO7kJrVUx49jY6NAjA6NprJKCoi+PCHP8zixYtZuXJlFqE6QZmZTSaVo6eyLEZRt912G1deeSU33XQTS5YsYcmSJVx//fVtndO9+MzMJpFrN1+7e/RUNjo2yvrN61n97tUtn/fkk08mItoNby9OUGZmk8jwyuG8Q0jNU3xmZlZITlBmadTabbTNXUjNrDZP8Zml0UO7kNrkFBFIyjuMuppdo/IIysysx82YMYOnn3468yKFLEUETz/9NDNmzEj9GY+gzMx63Lx58xgeHmb79u15h1LXjBkzmDdvXur3O0GZmfW4adOmccQRR+QdRuY8xWdmZoXkBGVmZoXkBGVmZoWkIld9TCRpO7A17zg65CDgX/MOooP6+fv183cDf79e1ivfbUFEzJ14sKcSVD+TtDEiluYdR6f08/fr5+8G/n69rNe/m6f4zMyskJygzMyskJygimNN3gF0WD9/v37+buDv18t6+rt5DcrMzArJIygzMyskJ6gCkfSXkh6WdK+kayS9Ku+YsiTp/ZIekDQuqWcriypJOl3SZkmPSvpU3vFkSdLfSHpK0v15x5I1SYdLulnSQ6X/T16Ud0xZkjRD0gZJ95S+36V5x9QKJ6hiuRE4PiLeAPwM+JOc48na/cCZwK15B5IFSVOB1cBvAscC50g6Nt+oMvUN4PS8g+iQl4FPRMRi4G3AR/vsf7sXgV+LiDcCS4DTJb0t35Ca5wRVIBHx/Yh4ufT0diB9298eEBEPRcTmvOPI0FuARyPisYgYBa4G3ptzTJmJiFuBf8s7jk6IiJGI+GnpzzuBh4DD8o0qO5F4tvR0WunRcwUHTlDFdT7wT3kHYXUdBjxR8XyYPvolN1lIWgicANyRcyiZkjRV0ibgKeDGiOi57+ftNrpM0g+Ag6u8tCoi1pfes4pkCmKom7FlIc336yPVti/tuX+lTmaSZgH/CHw8Ivpq2+SIGAOWlNayr5F0fET01HqiE1SXRcRp9V6XdC7wHuDXowfvAWj0/frMMHB4xfN5wC9zisWaJGkaSXIaiohv5x1Pp0TEM5J+RLKe2FMJylN8BSLpdOCTwBkRsSvveKyhO4HXSjpC0nTgg8C1OcdkKUgSsBZ4KCI+n3c8WZM0t1wFLGl/4DTg4VyDaoETVLF8GZgN3Chpk6Sv5R1QliS9T9IwcBJwnaTv5R1TO0oFLb8PfI9kkf1bEfFAvlFlR9JVwE+AoyUNS/pw3jFl6O3Ah4BfK/1d2yRpWd5BZegQ4GZJ95L8Q+rGiPhuzjE1zZ0kzMyskDyCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCsp4laaxUHny/pL+XNLPG+/6lxfMvlXR5G/E9W+P4wZKulvRzSQ9Kul7S61q9ThFIeqekX63x2jGSfiLpRUl/2O3YrHc5QVkvez4ilkTE8cAocGHli6Vu40RE1V+cjUTExoj4WPth7hWTgGuAH0XEoog4FvhT4DVZXicH7wRq/Xf+N+BjwGe7Fo31BSco6xc/Bo4q/Uv+Zkl/C9wHe0Yypdd+JOkfSvtuDZUSBpJOlPQvpf1zNkiaXXr/d0uvXyLpSkk3SXpE0u+Vjs+S9ENJP5V0n6RG3cxPBV6KiN03YUfEpoj4sRJ/WRoR3ifp7Iq4b5H0LUk/k/QZSQOlOO+TtKj0vm9I+pqkH5fe957S8RmS1pXee7ekU0vHz5P0bUk3lL7T/yrHJOk/lUY9Py2NTmeVjm+RdGnF9z1GSbPVC4H/VhrR/sfKLxwRT0XEncBLrfwPa5OXe/FZz5O0H8meTDeUDr2FZF+tX1R5+wnAcSQ9824D3i5pA/B3wNkRcaekOcDzVT77BpK9g14J3C3pOpJO0e+LiB2SDgJul3RtnT6KxwN31XjtTJK9e94IHATcKam8d9YbgcUko5HHgL+OiLco2WjvD4CPl963EHgHsIikk8BRwEcBIuL1ko4Bvl8xpbik9N/kRWCzpC+VvvungdMi4jlJnwRWAn9e+sy/RsSbJK0A/jAiLih1PXk2IjxKssw4QVkv21/JdgKQjKDWkkwzbaiRnCi9NgxQ+uxC4N+BkdK/8il3tS4Nriqtj4jngecl3UySCK8D/oekU4Bxku02XgM82cL3ORm4qtSF+v9KugU4EdgB3BkRI6W4fg58v/SZ+0hGZWXfiohx4BFJjwHHlM77pdJ3e1jSVqCcoH4YEf9eOu+DwALgVSQbMN5W+m8wnaTlUVm5sepdJEnVrCOcoKyXPR8RSyoPlH6hPlfnMy9W/HmM5O+ASLdNxsT3BDAAzAXeHBEvSdoCzKhzjgeA367xWrXtO8oq4x6veD7O3n+Pq8WY9ryV/z1ujIhzGnym/H6zjvAalFnS5flQSScClNafqv3ifW9pPedAkqKAO4FfAZ4qJadTSUYg9dwEvKK8hlW63omS3gHcCpytZKO5ucApwIYmv8v7JU0prUsdCWwunXegdK3XAfNLx2u5nWTq86jSZ2aqcZXhTpJGx2aZcYKySa+0XfvZwJck3QPcSPVR0AaSKb3bgcGI+CXJppJLJW0kSQJ1tzQorU29D/gNJWXmDwCXkKyJXQPcC9xDksj+OCKanSrcDNxCshvzhRHxAvAVYKqk+0jW2s6LiBdrnSAitgPnAVcp6YZ9O8lUYT3fAd5XrUhCSVn9MMk61qeVdEaf0+T3sknI3czNUpB0CQUvApD0DeC7EfEPecdilgWPoMzMrJA8gjIzs0LyCMrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArp/wMxKs/bQsy6UQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "\n",
    "for lab, col, mar in zip((0, 1, 2),\n",
    "                         ('blue', 'red', 'green'),\n",
    "                         ('o', 's', '^')):\n",
    "    plt.scatter(X_train_pca[y_train == lab, 0],\n",
    "                X_train_pca[y_train == lab, 1],\n",
    "                label=lab,\n",
    "                marker=mar,\n",
    "                c=col)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='height:100px;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Model Evaluation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wine_data\n\u001b[1;32m      3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m wine_data()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "from mlxtend.data import wine_data\n",
    "\n",
    "X, y = wine_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wine dataset.\n",
    "\n",
    "Source : https://archive.ics.uci.edu/ml/datasets/Wine\n",
    "\n",
    "Number of samples : 178\n",
    "\n",
    "Class labels : {0, 1, 2}, distribution: [59, 71, 48]\n",
    "\n",
    "Dataset Attributes:\n",
    "\n",
    "1. Alcohol\n",
    "2. Malic acid\n",
    "3. Ash\n",
    "4. Alcalinity of ash\n",
    "5. Magnesium\n",
    "6. Total phenols\n",
    "7. Flavanoids\n",
    "8. Nonflavanoid phenols\n",
    "9. Proanthocyanins\n",
    "10. Color intensity\n",
    "11. Hue\n",
    "12. OD280/OD315 of diluted wines\n",
    "13. Proline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      8\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m     10\u001b[0m pipe_kn \u001b[38;5;241m=\u001b[39m make_pipeline(StandardScaler(), \n\u001b[1;32m     11\u001b[0m                         PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     12\u001b[0m                         KNN(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m kfold \u001b[38;5;241m=\u001b[39m \u001b[43mStratifiedKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, (train, test) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kfold):\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "pipe_kn = make_pipeline(StandardScaler(), \n",
    "                        PCA(n_components=1),\n",
    "                        KNN(n_neighbors=3))\n",
    "\n",
    "kfold = StratifiedKFold(y=y_train, \n",
    "                        n_folds=10,\n",
    "                        random_state=1)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_kn.fit(X_train[train], y_train[train])\n",
    "    score = pipe_kn.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "          np.bincount(y_train[train]), score))\n",
    "    \n",
    "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[1;32m      3\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(estimator\u001b[38;5;241m=\u001b[39mpipe_kn,\n\u001b[1;32m      4\u001b[0m                          X\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[1;32m      5\u001b[0m                          y\u001b[38;5;241m=\u001b[39my_train,\n\u001b[1;32m      6\u001b[0m                          cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m                          n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCV accuracy scores: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m scores)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_kn,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=2)\n",
    "\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standardscaler': StandardScaler(),\n",
       " 'pca': PCA(n_components=1),\n",
       " 'kneighborsclassifier': KNeighborsClassifier(n_neighbors=3)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_kn.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9727272727272727\n",
      "{'kneighborsclassifier__n_neighbors': 7, 'pca__n_components': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "120 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 407, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 457, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 475, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=5 must be between 0 and min(n_samples, n_features)=4 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 407, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 457, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\", line 475, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=6 must be between 0 and min(n_samples, n_features)=4 with svd_solver='full'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/dsvb/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.92454545 0.88636364 0.91636364 0.91636364        nan        nan\n",
      " 0.91636364 0.93454545 0.91636364 0.95454545 0.94545455        nan\n",
      "        nan 0.94545455 0.93545455 0.91636364 0.95454545 0.95454545\n",
      "        nan        nan 0.95454545 0.90545455 0.93545455 0.97272727\n",
      " 0.96363636        nan        nan 0.96363636 0.91545455 0.92636364\n",
      " 0.94454545 0.95363636        nan        nan 0.95363636 0.92545455\n",
      " 0.92636364 0.92636364 0.93545455        nan        nan 0.93545455]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'pca__n_components': [1, 2, 3, 4, 5, 6, None],\n",
    "              'kneighborsclassifier__n_neighbors': [1, 3, 5, 7, 9, 11]}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_kn, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=2,\n",
    "                  refit=True)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
